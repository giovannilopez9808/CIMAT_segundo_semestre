{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giovanni Gamaliel López Padilla\n",
    "### Procesamiento de lenguaje natural\n",
    "### Tarea 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "#### Organización de la carpeta\n",
    "\n",
    "```bash\n",
    "├── Data\n",
    "│  ├── conferences\n",
    "│  │  ├── 2018-12-07\n",
    "│  │  ├── 2018-12-10\n",
    "│  │  ├── .........\n",
    "│  │  ├── 2021-01-21\n",
    "│  │  └── 2021-01-22\n",
    "│  ├── mex_train.txt\n",
    "│  ├── mex_train_labels.txt\n",
    "│  ├── mex_val.txt\n",
    "│  └── mex_val_labels.txt\n",
    "├── Modules\n",
    "│  ├── datasets.py\n",
    "│  ├── dictionary.py\n",
    "│  ├── functions.py\n",
    "│  ├── mañaneras.py\n",
    "│  ├── models.py\n",
    "│  ├── tweets.py\n",
    "│  └── vocabulary.py\n",
    "└── Tarea04.ipynb\n",
    "```\n",
    "\n",
    "Las funciones y clases contenidad en los archivos de la carpeta ``Modules`` se encuentran contenidas en el notebook.\n",
    "\n",
    "Si se quiere cambiar la posición de los archivos de datos debera modificarse la función ``obtain_parameters`` en los apartados correspondientes a cada base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import bigrams as bigrams_nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from numpy import array, log, zeros, exp\n",
    "from nltk import FreqDist,ngrams\n",
    "from unidecode import unidecode\n",
    "from tabulate import tabulate\n",
    "from numpy.linalg import norm\n",
    "from random import choice\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_parameters() -> dict:\n",
    "    \"\"\"\n",
    "    Obtiene las rutas y nombres de los archivos que seran usados\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        # Ruta de los archivos\n",
    "        \"path data\": \"Data/\",\n",
    "        \"path graphics\": \"Graphics/\",\n",
    "        \"path results\": \"Results/\",\n",
    "        \"path conferences\": \"Data/conferences/\",\n",
    "        # Archivos de entrenamiento\n",
    "        \"train\": {\n",
    "            \"data\": \"mex_train.txt\",\n",
    "            \"labels\": \"mex_train_labels.txt\"\n",
    "        },\n",
    "        # Archivos de validacion\n",
    "        \"validation\": {\n",
    "            \"data\": \"mex_val.txt\",\n",
    "            \"labels\": \"mex_val_labels.txt\"\n",
    "        },\n",
    "        \"max words\": 5000,\n",
    "        \"max bigrams\": 1000,\n",
    "        \"lambda list\": [[1/3, 1/3, 1/3],\n",
    "                        [0.4, 0.4, 0.2],\n",
    "                        [0.2, 0.4, 0.4],\n",
    "                        [0.5, 0.4, 0.1],\n",
    "                        [0.1, 0.4, 0.5]]\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Realiza la tokenizacion de un texto dado\n",
    "    ------------\n",
    "    Inputs:\n",
    "    text -> string de texto\n",
    "\n",
    "    ------------\n",
    "    Outputs:\n",
    "    aux -> lista de tokens\n",
    "    \"\"\"\n",
    "    # Expresión para obtener palabras\n",
    "    reg_exp = r\"<?/?[A-Z|a-z]+>?\"\n",
    "    tokenizer = TweetTokenizer().tokenize\n",
    "    text = unidecode(text)\n",
    "    # coniverto texto a minúsculas y limpio\n",
    "    aux = re.findall(reg_exp, text.lower())\n",
    "    aux = ' '.join(aux)\n",
    "    # tokenizo\n",
    "    aux = tokenizer(aux)\n",
    "    return aux\n",
    "\n",
    "\n",
    "def ls(path: str) -> list:\n",
    "    return sorted(listdir(path))\n",
    "\n",
    "\n",
    "def join_path(path: str, filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Une la direccion de un archivo con su nombre\n",
    "    \"\"\"\n",
    "    return \"{}{}\".format(path, filename)\n",
    "\n",
    "\n",
    "def mask_unknow(tweet: str, vocabulary: list) -> str:\n",
    "    \"\"\"\n",
    "    Enmascaramiento de una oración dado un vocabulario\n",
    "    -----------\n",
    "    Inputs:\n",
    "    + tweet -> string con el tweet a enmascarar\n",
    "    + vocabulary -> vocabulario de los datos de entrenamiento\n",
    "\n",
    "    ------------\n",
    "    Outputs:\n",
    "    tweet_mask -> string con el tweet enmascarado\n",
    "    \"\"\"\n",
    "    # Tokens del tweet dado\n",
    "    tokens = tokenize(tweet)\n",
    "    # Enmascaramiento de los tokens\n",
    "    tweet_mask = [word if word in vocabulary else \"<unk>\"\n",
    "                  for word in tokens]\n",
    "    # Union de los tokens\n",
    "    tweet_mask = \" \".join(tweet_mask)\n",
    "    return tweet_mask\n",
    "\n",
    "\n",
    "class dictionary_class:\n",
    "    \"\"\"\n",
    "    Métodos para crear diccionarios con diferentes informaciones\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def build_word_index(self, vocabulary: list) -> dict:\n",
    "        \"\"\"\n",
    "        Crea un diccionario con la posición de mayor a menor frecuencia de cada palabra. La llave es la palabra a consultar\n",
    "        \"\"\"\n",
    "        # Inicializacion del diccionario\n",
    "        index = dict()\n",
    "        # Inicializacion de la posicion\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            index[word] = i\n",
    "        return index\n",
    "\n",
    "    def build_with_words_and_documents(self, words: dict, data: list) -> dict:\n",
    "        \"\"\"\n",
    "        Crea un diccionario el cual contendra de forma ordenada el indice de cada palabra y su numero de frecuencias en una coleccion\n",
    "        \"\"\"\n",
    "        freq_word_per_document = dict()\n",
    "        word_count = dict()\n",
    "        for i, tweet in enumerate(data):\n",
    "            word_count[i] = 0\n",
    "        for word in words:\n",
    "            freq_word_per_document[word] = word_count\n",
    "        return freq_word_per_document\n",
    "\n",
    "    def obtain_index_word(self, index_word: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Invierte los valores de un diccionario dado. Los values pasan a ser keys y viceversa\n",
    "        \"\"\"\n",
    "        invert_index = {}\n",
    "        for word in index_word:\n",
    "            invert_index[index_word[word]] = word\n",
    "        return invert_index\n",
    "\n",
    "    def sort_dict(self, data: dict, reverse: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Ordena un diccionario\n",
    "        \"\"\"\n",
    "        aux = sorted(data.items(),\n",
    "                     key=lambda item: item[1], reverse=reverse)\n",
    "        dict_sort = {}\n",
    "        for word, value in aux:\n",
    "            dict_sort[word] = value\n",
    "        return dict_sort\n",
    "\n",
    "\n",
    "class vocabulary_class:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def obtain(self, data: list, max_words: int) -> dict:\n",
    "        \"\"\"\n",
    "        Obtiene la lista de una distribucion de frecuencias de palabras ordenada de mayor a menor a partir de una lista de oraciones\n",
    "        \"\"\"\n",
    "        # Inicializacion de la lista que guardara los tokens\n",
    "        corpus = []\n",
    "        for tweet in data:\n",
    "            # Creacion y guardado de los tokens\n",
    "            corpus += tokenize(tweet)\n",
    "        # Creacion de la distribucion de frecuencias\n",
    "        vocabulary = FreqDist(corpus)\n",
    "        vocabulary = self.sort_freqdist(vocabulary)\n",
    "        # print(vocabulary)\n",
    "        vocabulary = self.split_data(vocabulary, max_words)\n",
    "        return vocabulary\n",
    "\n",
    "    def obtain_with_bigrams(self, data: list, max_bigrams: int) -> list:\n",
    "        \"\"\"\n",
    "        Obtiene la lista de una distribucion de frecuencias de palabras ordenada de mayor a menor a partir de una lista de oraciones\n",
    "        \"\"\"\n",
    "        # Inicializacion de la lista que guardara los tokens\n",
    "        corpus_bigrams = []\n",
    "        for tweet in data:\n",
    "            # Creacion y guardado de los tokens\n",
    "            corpus_bigrams += bigrams_nltk(tokenize(tweet))\n",
    "        # Creacion de la distribucion de frecuencias\n",
    "        vocabulary = FreqDist(corpus_bigrams)\n",
    "        vocabulary = self.sort_freqdist(vocabulary)\n",
    "        vocabulary = self.split_data(vocabulary, max_bigrams)\n",
    "        return vocabulary\n",
    "\n",
    "    def sort_freqdist(self, vocabulary: FreqDist) -> list:\n",
    "        \"\"\"\n",
    "        Ordena la lista de distribucion de frecuencias de palabras de mayor frecuencia a menor\n",
    "        \"\"\"\n",
    "        aux = {}\n",
    "        for word in vocabulary:\n",
    "            aux[word] = vocabulary[word]\n",
    "        aux = dictionary_class().sort_dict(aux)\n",
    "        return aux\n",
    "\n",
    "    def split_data(self, data: dict, max_words: int) -> list:\n",
    "        \"\"\"\n",
    "        Realiza la separacion de elementos en una lista dado el numero de elementos que se quieren conservar\n",
    "        \"\"\"\n",
    "        aux = {}\n",
    "        for i, word in enumerate(data):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            aux[word] = data[word]\n",
    "        return aux\n",
    "\n",
    "\n",
    "class probability_model_class:\n",
    "    \"\"\"\n",
    "    Contenido para enmascarar palabras que no estan contenidas en un vocabulario y calculo de las probabilidades de unigramas, bigramas y trigramas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def obtain_unigram_probabilities_Laplace(self, data: list) -> dict:\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades de cada unigrama en los datos dado\n",
    "        --------------\n",
    "        Inputs:\n",
    "        + data -> lista de strings con cada tweet\n",
    "\n",
    "        Output:\n",
    "        + probability -> diccionario con las probabilidades de cada palabra en el vocabulario\n",
    "        \"\"\"\n",
    "        # Tokens de cada oracion\n",
    "        tokens = []\n",
    "        for tweet in data:\n",
    "            # Token de cada tweet\n",
    "            tokens += tokenize(tweet)\n",
    "        # Numero de palabras en el documento\n",
    "        self.words_len = len(tokens)\n",
    "        # Frecuencias de las palabras\n",
    "        self.unigram_fdist = FreqDist(tokens)\n",
    "        # Tamaño del vocabulario\n",
    "        n_vocabulary = len(self.unigram_fdist)\n",
    "        # Probabilidades de unigramas\n",
    "        probability = {\n",
    "            word: (count + 1.0) / (self.words_len + n_vocabulary)\n",
    "            for word, count in self.unigram_fdist.items()\n",
    "        }\n",
    "        self.unigram_probability = probability.copy()\n",
    "        return probability\n",
    "\n",
    "    def obtain_ngrams_probabilities_Laplace(self, data: list, ngram: int) -> dict:\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades de cada ngrama en los datos dado\n",
    "        --------------\n",
    "        Inputs:\n",
    "        + data -> lista de strings con cada tweet\n",
    "        + ngram -> entero que indica el número de ngramas a calcular\n",
    "\n",
    "        Output:\n",
    "        + probability -> diccionario con las probabilidades de cada bigrama en el vocabulario\n",
    "        \"\"\"\n",
    "        # Creacion de la lista de tokens\n",
    "        tokens = []\n",
    "        for tweet in data:\n",
    "            # Tokens de cada tweet\n",
    "            tokens += tokenize(tweet)\n",
    "        self.tokens = tokens.copy()\n",
    "        # ngramas en el documento\n",
    "        n_grams = ngrams(tokens, n=ngram)\n",
    "        # frecuencia de cada ngrama\n",
    "        ngram_fdist = FreqDist(n_grams)\n",
    "        # numero total de ngramas\n",
    "        ngram_len = len(ngram_fdist)\n",
    "        # inicializacion de la probabilidades\n",
    "        probabilities = {}\n",
    "        # Apartado para bigrama\n",
    "        if ngram == 2:\n",
    "            for (word_i, word_j), count in ngram_fdist.items():\n",
    "                # Frecuencia de la palabra anterior en el bigrama\n",
    "                count_word_i = self.unigram_fdist[word_i]\n",
    "                # Probabilidad del bigrama\n",
    "                probabilities[(word_j, word_i)] = (\n",
    "                    count + 1.0) / (count_word_i + ngram_len)\n",
    "            self.bigram_probability = probabilities.copy()\n",
    "        # Apartado para trigrama\n",
    "        if ngram == 3:\n",
    "            # bigramas en el documento\n",
    "            bigrams = ngrams(tokens, n=2)\n",
    "            # frecuencias de cada bograma\n",
    "            self.bigram_fdist = FreqDist(bigrams)\n",
    "            for (word_i, word_j, word_k), count in ngram_fdist.items():\n",
    "                # frecuencia del bigrama\n",
    "                count_fs = self.bigram_fdist[(word_i, word_j)]\n",
    "                # Suavizado con laplace\n",
    "                probabilities[(word_k, word_i, word_j)] = (\n",
    "                    count + 1.0) / (count_fs + ngram_len)\n",
    "            self.trigram_probability = probabilities.copy()\n",
    "        return probabilities\n",
    "\n",
    "    def obtain_unigram_probability(self, word: str) -> float:\n",
    "        \"\"\"\n",
    "        Obtiene la probabilidad que tiene un tweet siguiendo una probabilidad de unigramas\n",
    "        --------------\n",
    "        Input:\n",
    "        + tweet -> string del tweet\n",
    "        \"\"\"\n",
    "        if not word in self.unigram_probability:\n",
    "            word = \"<unk>\"\n",
    "        probability = self.unigram_probability[word]\n",
    "        return probability\n",
    "\n",
    "    def compute_ngram_probability(self,\n",
    "                                  tweet: str,\n",
    "                                  vocabulary: list,\n",
    "                                  ngram: int = 2) -> float:\n",
    "        \"\"\"\n",
    "        Calculo de la probabilidad de la oracion dada\n",
    "        ----------\n",
    "        Inputs:\n",
    "        + tweet -> string tweet a calcular su probabilidad\n",
    "        + vocabulary -> vocabulario de los datos de entrenamiento\n",
    "        + ngram -> entero que indica la cantidad de ngramas a tomar\n",
    "\n",
    "        -----------\n",
    "        Output:\n",
    "        probability -> probabilidad del tweet dado\n",
    "        \"\"\"\n",
    "        # enmascaro oracion\n",
    "        tweet = mask_unknow(tweet, vocabulary)\n",
    "        # Concateno inicio y fin de oración\n",
    "        s_init = \"<s>\"\n",
    "        s_fin = \"</s>\"\n",
    "        tweet = \"{}{}{}\".format(s_init, tweet, s_fin)\n",
    "        tweet = tokenize(tweet)\n",
    "        # Tamaño del vocabulario\n",
    "        vocabulary_len = len(vocabulary)\n",
    "        probability = 1\n",
    "        # Apartado para bigrama\n",
    "        if ngram == 2:\n",
    "            # Frecuencia de los unigramas\n",
    "            for i in range(len(tweet) - 1):\n",
    "                word_i = tweet[i]\n",
    "                word_j = tweet[i + 1]\n",
    "                if (word_j, word_i) in self.bigram_probability:\n",
    "                    probability *= self.bigram_probability[(word_j, word_i)]\n",
    "                # Si la palabra no se encuentra se da una probabilidad\n",
    "                else:\n",
    "                    freq_word_i = self.unigram_fdist[word_i]\n",
    "                    probability *= 1.0 / (freq_word_i + vocabulary_len)\n",
    "        # Apartado para trigramas\n",
    "        if ngram == 3:\n",
    "            # Bigramas en la oracion\n",
    "            bigrams = ngrams(self.tokens, n=2)\n",
    "            # Freceucnia de bigramas\n",
    "            self.bigrams_fdist = FreqDist(bigrams)\n",
    "            # Tamaño e bigramas\n",
    "            bigram_len = len(self.bigrams_fdist)\n",
    "            for i in range(len(tweet) - 2):\n",
    "                word_i = tweet[i]\n",
    "                word_j = tweet[i + 1]\n",
    "                word_k = tweet[i + 2]\n",
    "                if (word_k, word_i, word_j) in self.trigram_probability:\n",
    "                    probability *= self.trigram_probability[(\n",
    "                        word_k, word_i, word_j)]\n",
    "                # Si no se encuentra se da una probabilidad\n",
    "                else:\n",
    "                    count_fs = 0\n",
    "                    if (word_i, word_j) in self.bigrams_fdist:\n",
    "                        count_fs = self.bigrams_fdist[(word_i, word_j)]\n",
    "                    conditional_prop = 1 / (count_fs + bigram_len)\n",
    "                    probability *= conditional_prop\n",
    "        return probability\n",
    "\n",
    "    def obtain_ngram_probability(self, ngram: list) -> float:\n",
    "        \"\"\"\n",
    "        Obtiene la probabilidad de un ngrama dado\n",
    "        -----------\n",
    "        Inputs:\n",
    "        + ngram -> lista de ngramas\n",
    "\n",
    "        -----------\n",
    "        Output:\n",
    "        + probability -> probabilidad del ngrama dado\n",
    "        \"\"\"\n",
    "        probability = 1.0\n",
    "        ngram_len = len(ngram)\n",
    "        # Caso para bigrama\n",
    "        if ngram_len == 2:\n",
    "            for i in range(ngram_len - 1):\n",
    "                word_i = ngram[i]\n",
    "                word_j = ngram[i + 1]\n",
    "                if (word_j, word_i) in self.bigram_probability:\n",
    "                    probability *= self.bigram_probability[(word_j, word_i)]\n",
    "                # Si la probabilidad no existe se da con al menos un conteo\n",
    "                else:\n",
    "                    freq_word_i = self.unigram_fdist[word_i]\n",
    "                    probability *= 1.0 / (freq_word_i + self.words_len)\n",
    "        # Caso para trigramas\n",
    "        if ngram_len == 3:\n",
    "            for i in range(ngram_len - 2):\n",
    "                word_i = ngram[i]\n",
    "                word_j = ngram[i + 1]\n",
    "                word_k = ngram[i + 2]\n",
    "                if (word_k, word_i, word_j) in self.trigram_probability:\n",
    "                    probability *= self.trigram_probability[(\n",
    "                        word_k, word_i, word_j)]\n",
    "                # Si la probabilidad no existe se da con al menos un conteo\n",
    "                else:\n",
    "                    count_fs = 0.0\n",
    "                    if (word_i, word_j) in self.bigram_fdist:\n",
    "                        count_fs = self.bigram_fdist[(word_i, word_j)]\n",
    "                    conditional_prop = 1.0 / (count_fs + self.words_len)\n",
    "                    probability *= conditional_prop\n",
    "        return probability\n",
    "\n",
    "\n",
    "class language_model_class:\n",
    "\n",
    "    def __init__(self, data_tr: list, data_test: list, data_val: list, vocabulary: dict):\n",
    "        self.probability_model = probability_model_class()\n",
    "        self.data_tr = data_tr\n",
    "        self.data_test = data_test\n",
    "        self.data_val = data_val\n",
    "        self.vocabulary = vocabulary.keys()\n",
    "        self.obtain_probabilities()\n",
    "\n",
    "    def obtain_probabilities(self) -> None:\n",
    "        self.unigram_probability = self.probability_model.obtain_unigram_probabilities_Laplace(\n",
    "            self.data_tr)\n",
    "        self.bigram_probability = self.probability_model.obtain_ngrams_probabilities_Laplace(\n",
    "            self.data_tr,\n",
    "            ngram=2,\n",
    "        )\n",
    "        self.tigram_probability = self.probability_model.obtain_ngrams_probabilities_Laplace(\n",
    "            self.data_tr,\n",
    "            ngram=3,\n",
    "        )\n",
    "        # Preparo modelo para evaluación\n",
    "        tokens = []\n",
    "        for tweet in self.data_tr:\n",
    "            tokens += tokenize(tweet)\n",
    "        # Total de palabras\n",
    "        self.words_len = len(tokens)\n",
    "        bigrams = ngrams(tokens, n=2)\n",
    "        # Frecuencias bigramas\n",
    "        self.bigram_fdist = FreqDist(bigrams)\n",
    "        # Frecuencias unigramas\n",
    "        self.unigram_fdist = FreqDist(tokens)\n",
    "\n",
    "    def compute_perplexity(self, lambda_values: list, use_data_test: bool = True) -> float:\n",
    "        tokens = []\n",
    "        if use_data_test:\n",
    "            data = self.data_test\n",
    "        else:\n",
    "            data = self.data_val\n",
    "        for tweet in data:\n",
    "            tokens += tokenize(tweet)\n",
    "        trigrams = ngrams(tokens, n=3)\n",
    "        perplexity = 0.0\n",
    "        for (word_i, word_j, word_k) in trigrams:\n",
    "            aux = 0.0\n",
    "            aux += lambda_values[0] * self.probability_model.obtain_ngram_probability(\n",
    "                (word_i, word_j, word_k),)\n",
    "            aux += lambda_values[1] * self.probability_model.obtain_ngram_probability(\n",
    "                (word_i, word_j),)\n",
    "            aux += lambda_values[2] * self.probability_model.obtain_unigram_probability(\n",
    "                word_i)\n",
    "            perplexity += log(aux)\n",
    "        perplexity = -perplexity / self.words_len\n",
    "        return perplexity\n",
    "\n",
    "    def tweet_probability(self, tweet: str, lambda_values: list, add_s_tokens: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de un tweet por medio de la interpolacion\n",
    "        ----------------\n",
    "        Inputs:\n",
    "        + tweet -> string del tweet a calcular su probabilidad\n",
    "        + lambda_values -> lista de lambdas para los pesos de cada ngrama\n",
    "\n",
    "        ----------------\n",
    "        Outputs:\n",
    "        + probability -> probabilidad del tweet dado\n",
    "        \"\"\"\n",
    "        # Enmascaro palabras desconocidas\n",
    "        if add_s_tokens:\n",
    "            tweet = mask_unknow(tweet, self.vocabulary)\n",
    "            tweet = \"<s>{}</>\".format(tweet)\n",
    "        tokens = tokenize(tweet)\n",
    "        trigrams = ngrams(tokens, n=3)\n",
    "        probability = 1.0\n",
    "        for (word_i, word_j, word_k) in trigrams:\n",
    "            aux = 0\n",
    "            # Compruebo valores de lambda\n",
    "            if lambda_values[0] != 0:\n",
    "                aux += lambda_values[0] * self.probability_model.obtain_ngram_probability(\n",
    "                    (word_i, word_j, word_k),)\n",
    "            if lambda_values[1] != 0:\n",
    "                aux += lambda_values[1] * self.probability_model.obtain_ngram_probability(\n",
    "                    (word_i, word_j),)\n",
    "            if lambda_values[2] != 0:\n",
    "                aux += lambda_values[2] * self.probability_model.obtain_unigram_probability(\n",
    "                    word_i)\n",
    "            probability *= aux\n",
    "        return probability\n",
    "\n",
    "    def apply_expectation_maximization(self, lambda_test: list = [], iterations: int = 5) -> array:\n",
    "        results = []\n",
    "        ngrams = 3\n",
    "        if not len(lambda_test):\n",
    "            lambda_test = [1/ngrams for i in range(ngrams)]\n",
    "        perplexity = exp(self.compute_perplexity(lambda_test))\n",
    "        results += [[\"Inicio\",\n",
    "                     lambda_test.copy(),\n",
    "                     sum(lambda_test),\n",
    "                     perplexity]]\n",
    "        data_len = len(self.data_val)\n",
    "        # Vectores de distribuciones q_m\n",
    "        dist = zeros((data_len, ngrams), dtype=float)\n",
    "        for iteration in range(iterations):\n",
    "            # Ciclo sobre tokens de validación\n",
    "            for i, tweet in enumerate(self.data_val):\n",
    "                dist[i, 0] = self.tweet_probability(tweet,\n",
    "                                                    [lambda_test[0], 0, 0],\n",
    "                                                    add_s_tokens=False)\n",
    "                dist[i, 1] = self.tweet_probability(tweet,\n",
    "                                                    [0, lambda_test[1], 0],\n",
    "                                                    add_s_tokens=False)\n",
    "                dist[i, 2] = self.tweet_probability(tweet,\n",
    "                                                    [0, 0, lambda_test[2]],\n",
    "                                                    add_s_tokens=False)\n",
    "                # Normalizo vector\n",
    "                dist[i] = dist[i] / norm(dist[i])\n",
    "            # Update lambdas\n",
    "            for i in range(ngrams):\n",
    "                lambda_test[i] = sum(dist[:, i]) / data_len\n",
    "            perplexity = exp(self.compute_perplexity(lambda_test))\n",
    "            results += [[\"Iteración {}\".format(iteration+1),\n",
    "                         lambda_test.copy(),\n",
    "                         sum(lambda_test),\n",
    "                         perplexity]]\n",
    "\n",
    "        print(tabulate(results,\n",
    "                       headers=[\"Iteracion\", \"lambdas\", \"Suma\", \"Perplexidad\"]))\n",
    "        return lambda_test\n",
    "\n",
    "\n",
    "class tweetear_model:\n",
    "    def __init__(self, language_model: language_model_class, lambdas: list):\n",
    "        self.language_model = language_model\n",
    "        self.lambdas = lambdas\n",
    "\n",
    "    def autocomplete(self, init_text: list):\n",
    "        # Creo todas las posibles oraciones\n",
    "        tweets = []\n",
    "        for word in self.language_model.vocabulary:\n",
    "            value = \"{} {}\".format(init_text, word)\n",
    "            tweets += [value]\n",
    "        probabilities = []\n",
    "        for i, tweet in enumerate(tweets):\n",
    "            probabilities += [[self.language_model.tweet_probability(tweet,\n",
    "                                                                     self.lambdas), i]]\n",
    "        # Ordeno oraciones por probabilidad\n",
    "        probabilities.sort(reverse=True)\n",
    "        tweet = tweets[probabilities[0][1]]\n",
    "        return tweet\n",
    "\n",
    "    def write(self, init_text: list, max_words: int = 50) -> str:\n",
    "        text = tokenize(init_text)\n",
    "        result = text.copy()\n",
    "        for i in range(max_words):\n",
    "            tweet = self.autocomplete(\" \".join(text))\n",
    "            words = tokenize(tweet)\n",
    "            word = words[-1]\n",
    "            text.pop(0)\n",
    "            text.append(word)\n",
    "            result += [word]\n",
    "            if word == '</s>':\n",
    "                break\n",
    "        result = \" \".join(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class tweets_data:\n",
    "    def __init__(self, parameters: dict) -> None:\n",
    "        self.vocabulary_model = vocabulary_class()\n",
    "        self.dictionary = dictionary_class()\n",
    "        self.parameters = parameters\n",
    "        self.read()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        self.add_s_tokens()\n",
    "        self.obtain_vocabulary(use_mask=True)\n",
    "        self.obtain_word_index()\n",
    "        self.obtain_index_word()\n",
    "        self.data_tr_mask = self.mask_tweets(self.data_tr_mask)\n",
    "        self.data_val_mask = self.mask_tweets(self.data_val_mask)\n",
    "        self.obtain_vocabulary(use_mask=True)\n",
    "        self.obtain_word_index()\n",
    "        self.obtain_index_word()\n",
    "        self.obtain_data_test()\n",
    "        self.language_model = language_model_class(self.data_tr_mask,\n",
    "                                                   self.data_test_mask,\n",
    "                                                   self.data_val_mask,\n",
    "                                                   self.vocabulary)\n",
    "\n",
    "    def get_texts_from_file(self, path_data: str, path_labels: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Obtiene una lista de oraciones a partir de un texto con sus respectivas etiquetas\n",
    "        \"\"\"\n",
    "        # Inicilizacion de las listas\n",
    "        text = []\n",
    "        labels = []\n",
    "        # Apertura de los archivos\n",
    "        with open(path_data, \"r\") as f_data, open(path_labels, \"r\") as f_labels:\n",
    "            # Recoleccion de las oraciones\n",
    "            for tweet in f_data:\n",
    "                text += [tweet]\n",
    "            # Recoleccion de las etiquedas\n",
    "            for label in f_labels:\n",
    "                labels += [label]\n",
    "        # Etiquedas a enteros\n",
    "        labels = list(map(int, labels))\n",
    "        return text, labels\n",
    "\n",
    "    def read(self) -> None:\n",
    "        \"\"\"\n",
    "        Lectura de los datos de entrenamiento y validacion\n",
    "        \"\"\"\n",
    "        # Definicion de las rutas de cada archivo de datos y validacion\n",
    "        path_data_tr = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"train\"][\"data\"],\n",
    "        )\n",
    "        path_label_tr = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"train\"][\"labels\"],\n",
    "        )\n",
    "        path_data_val = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"validation\"][\"data\"],\n",
    "        )\n",
    "        path_label_val = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"validation\"][\"labels\"],\n",
    "        )\n",
    "        # Lectura de las oraciones y etiquetas de los datos de entrenamiento\n",
    "        self.data_tr, self.labels_tr = self.get_texts_from_file(\n",
    "            path_data_tr,\n",
    "            path_label_tr,\n",
    "        )\n",
    "        # Lectura de las oraciones y etiquetas de los datos de validación\n",
    "        self.data_val, self.labels_val = self.get_texts_from_file(\n",
    "            path_data_val,\n",
    "            path_label_val,\n",
    "        )\n",
    "\n",
    "    def add_s_tokens(self) -> None:\n",
    "        self.data_tr_mask = [\"<s>{}</s>\".format(tweet)\n",
    "                             for tweet in self.data_tr]\n",
    "        self.data_val_mask = [\"<s>{}</s>\".format(tweet)\n",
    "                              for tweet in self.data_val]\n",
    "\n",
    "    def obtain_vocabulary(self, use_mask: bool) -> None:\n",
    "        if use_mask:\n",
    "            data = self.data_tr_mask\n",
    "        else:\n",
    "            data = self.data_tr\n",
    "        self.vocabulary = self.vocabulary_model.obtain(data,\n",
    "                                                       self.parameters[\"max words\"])\n",
    "\n",
    "    def obtain_word_index(self) -> None:\n",
    "        self.word_index = self.dictionary.build_word_index(self.vocabulary)\n",
    "\n",
    "    def obtain_index_word(self) -> None:\n",
    "        self.index_word = self.dictionary.obtain_index_word(self.word_index)\n",
    "\n",
    "    def mask_tweets(self, tweets: list) -> None:\n",
    "        tweets_mask = []\n",
    "        for tweet in tweets:\n",
    "            tweet_mask = mask_unknow(tweet,\n",
    "                                     self.vocabulary.keys())\n",
    "            tweets_mask += [tweet_mask]\n",
    "        return tweets_mask\n",
    "\n",
    "    def obtain_data_test(self) -> None:\n",
    "        self.data_tr_mask, self.data_test_mask = train_test_split(self.data_tr_mask,\n",
    "                                                                  train_size=0.89,\n",
    "                                                                  test_size=0.11,\n",
    "                                                                  random_state=12345)\n",
    "\n",
    "    def obtain_perplexity(self, use_data_test: bool) -> None:\n",
    "        results = []\n",
    "        for lambda_i in self.parameters[\"lambda list\"]:\n",
    "            perplexity = self.language_model.compute_perplexity(lambda_i,\n",
    "                                                                use_data_test=use_data_test)\n",
    "            results += [[lambda_i, exp(perplexity)]]\n",
    "        print(tabulate(results, headers=[\"Lambda\", \"Perplexity\"]))\n",
    "\n",
    "\n",
    "class AMLO_conferences_model(tweets_data):\n",
    "    def __init__(self, parameters: dict) -> None:\n",
    "        self.vocabulary_model = vocabulary_class()\n",
    "        self.dictionary = dictionary_class()\n",
    "        self.parameters = parameters\n",
    "        self.read()\n",
    "        self.obtain_data_val()\n",
    "        self.initialize()\n",
    "\n",
    "    def read(self) -> list:\n",
    "        \"\"\"\n",
    "        Realiza la lectura de todas las conferencias y las reune en un solo string\n",
    "        Input:\n",
    "            String: path -> Direccion donde se encuentran todos los archivos\n",
    "\n",
    "        Output:\n",
    "            String: Texto plano\n",
    "        \"\"\"\n",
    "        files = ls(self.parameters[\"path conferences\"])\n",
    "        self.data = []\n",
    "        for file in files:\n",
    "            # Direccion y nombre del archivo\n",
    "            filename = join_path(self.parameters[\"path conferences\"],\n",
    "                                 file)\n",
    "            # Apertura del archivo\n",
    "            file_data = open(filename, \"r\", encoding=\"utf-8\")\n",
    "            file_text = file_data.read()\n",
    "            file_text = file_text.lower()\n",
    "            file_text = unidecode(file_text)\n",
    "            file_text = tokenize(file_text)\n",
    "            file_text = \" \".join(file_text)\n",
    "            # Concadenacion del texto\n",
    "            self.data += [file_text]\n",
    "            # Cierre del texto\n",
    "            file_data.close()\n",
    "\n",
    "    def obtain_data_val(self) -> None:\n",
    "        self.data_tr, self.data_val = train_test_split(self.data,\n",
    "                                                       train_size=0.9,\n",
    "                                                       test_size=0.1,\n",
    "                                                       random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Modelos de lenguaje y evaluación\n",
    "##### Punto 1\n",
    "Preprocese todos los tuits de agresividad (positivos y negativos) según su intu- ición para construir un buen corpus para un modelo de lenguaje (e.g., solo palabras en minúscula, etc.). Agregue tokens especiales de ``<s>`` y ``</s>`` según usted considere (e.g., al inicio y final de cada tuit). Defina su vocabulario y enmascare con ``<unk>`` toda palabra que no esté en su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.datasets import obtain_parameters\n",
    "from Modules.tweets import tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = obtain_parameters()\n",
    "tweets = tweets_data(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 2\n",
    "\n",
    "Entrene tres modelos de lenguaje sobre todos los tuits: $𝑃_{𝑢𝑛𝑖𝑔𝑟𝑎𝑚𝑎𝑠}(𝑤_1^𝑛)$, $𝑃_{𝑏𝑖𝑔𝑟𝑎𝑚𝑎𝑠}(𝑤_1^𝑛)$, $𝑃_{𝑡𝑟𝑖𝑔𝑟𝑎𝑚𝑎𝑠}(𝑤_1^𝑛)$. Para cada uno proporcione una interfaz (función) sencilla para $𝑃_{𝑛−𝑔𝑟𝑎𝑚𝑎}(𝑤_1^𝑛)$ y $𝑃_{𝑛−𝑔𝑟𝑎𝑚𝑎}(𝑤_1^𝑛|𝑤_{𝑛−𝑁 +1}^{n-1})$. Los modelos deben tener una estrategia común para lidiar consecuencias no vistas. Puede optar por un suavizamiento Laplace o un Good-Turing discounting. Muestre un par de ejemplos de como funciona, al menos uno con una palabra fuera del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = tweets.language_model\n",
    "probability = language_model.probability_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023423631608247637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_unigram_probability(\"bien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013655031879247502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_unigram_probability(\"hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1070641765103124e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"bueno\", \"esto\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1075668970405812e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"hola\", \"como\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1077018509697929e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"como\", \"estas\", \"plataformas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1077141211396162e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"hola\", \"como\", \"estas\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 3\n",
    "\n",
    "Construya un modelo interpolado con valores $\\lambda$ fijos:\n",
    "\n",
    "$$\n",
    " \\hat{P}(w_𝑛 |𝑤_{𝑛−2}𝑤_{𝑛−1}) = \\lambda_1 𝑃(𝑤_𝑛 |𝑤_{𝑛−2}𝑤_{𝑛−1}) + \\lambda_2 𝑃(𝑤_𝑛 |𝑤_{𝑛−2}𝑤_{𝑛−1}) + \\lambda_3 𝑃(𝑤_𝑛) \\nonumber\n",
    "$$ \n",
    "\n",
    "Para ello experimente con el modelo en particiones estratificadas de 80%, 10% y 10% para entrenar (train), ajuste de parámetros (val) y prueba (test) respectivamente. Muestre como bajan o suben las perplejidades en validación, finalmente pruebe una vez en test. Para esto puede explorar algunos valores $\\lambda$ y elija el mejor, i.e., \n",
    "$$\n",
    "\\lambda_1 = \\left[\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\right] \\\\\n",
    "\\lambda_2 = [0.4, 0.4, 0.2] \\\\ \n",
    "\\lambda_3 = [0.2, 0.4, 0.4] \\\\ \n",
    "\\lambda_4 = [0.5, 0.4, 0.1] \\\\ \n",
    "\\lambda_5 =[0.1, 0.4, 0.5] \\\\ \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda                                                          Perplexity\n",
      "------------------------------------------------------------  ------------\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]       2.2506\n",
      "[0.4, 0.4, 0.2]                                                    2.35088\n",
      "[0.2, 0.4, 0.4]                                                    2.20592\n",
      "[0.5, 0.4, 0.1]                                                    2.48767\n",
      "[0.1, 0.4, 0.5]                                                    2.1582\n"
     ]
    }
   ],
   "source": [
    "tweets.obtain_perplexity(use_data_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda                                                          Perplexity\n",
      "------------------------------------------------------------  ------------\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]       2.15777\n",
      "[0.4, 0.4, 0.2]                                                    2.25321\n",
      "[0.2, 0.4, 0.4]                                                    2.11478\n",
      "[0.5, 0.4, 0.1]                                                    2.38302\n",
      "[0.1, 0.4, 0.5]                                                    2.06914\n"
     ]
    }
   ],
   "source": [
    "tweets.obtain_perplexity(use_data_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Generación de texto\n",
    "\n",
    "#### Punto 1\n",
    "\n",
    "Proponga una estrategia con base en Expectation Maximization para encontrar buenos valores de interpolación en $\\hat{P}$ usando todo el dataset de agresividad. Para ello experimente con el modelo en particiones de 80%, 10% y 10% para entrenar (train), ajustar parámetros (val) y probar (test) respectivamente. 1 Muestre como bajan las perplejidades en 5 iteraciones que usted elija (de todas las que sean necesarias de acuerdo a su EM) en validación, y pruebe una vez en test. Sino logra hacer este punto, haga los siguientes dos con el modelo de lenguaje con $\\lambda$ fijos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion    lambdas                                                               Suma    Perplexidad\n",
      "-----------  ------------------------------------------------------------------  ------  -------------\n",
      "Inicio       [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]             1        2.2506\n",
      "Iteración 1  [1.0751024666888301e-09, 2.9347965000825594e-08, 0.99999999999994]       1        2.02979\n",
      "Iteración 2  [1.2952031643886892e-36, 1.5460152938022499e-31, 1.0]                    1        2.02979\n",
      "Iteración 3  [2.2646548008525604e-117, 2.260066097622663e-101, 1.0]                   1        2.02979\n",
      "Iteración 4  [0.0, 7.0606259637826e-311, 1.0]                                         1        2.02979\n",
      "Iteración 5  [0.0, 0.0, 1.0]                                                          1        2.02979\n"
     ]
    }
   ],
   "source": [
    "lambdas = tweets.language_model.apply_expectation_maximization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.models import tweetear_model\n",
    "tweetear = tweetear_model(tweets.language_model, [1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 2\n",
    "\n",
    "Haga una función \"tuitear\" con base en su modelo de lenguaje $\\hat{P}$ del último punto. El modelo deberá poder parar automáticamente cuando genere el símbolo de terminación de tuit al final (e.g., ``</s>``), o 50 palabras. Proponga algo para que en los últimos tokens sea más probable generar el token ``</s>``. Muestre al menos cinco ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> me caga que me <unk> </s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hola pinche putita te pones bien cachonda hija de tu puta madre </s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> gracias facebook pero no son personas que <unk> </s>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> GRACIAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> gracias por resolver mi duda existencial </s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> gracias por\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> pisando <unk> </s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> pisando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> vale verga </s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> vale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 3\n",
    "Use la intuición que ha ganado en esta tarea y los datos de las mañaneras para entrenar un modelo de lenguaje AMLO. Haga una un función \"dar_conferencia()\". Generé un discurso de 300 palabras y detenga al modelo de forma abrupta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.mañaneras import AMLO_conferences_model\n",
    "parameters[\"max words\"]=20000\n",
    "conferences = AMLO_conferences_model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetear = tweetear_model(conferences.language_model, [1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'presidente es que se <unk> a la gente que no se puede hacer una revision de los estados unidos y canada y'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"presidente es\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buenos dias hoy vamos a tener una reunion con el gobierno de mexico y en el caso de la conferencia de prensa matutina del presidente andres manuel lopez obrador si pero no es un asunto de los estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"buenos dias hoy\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 4\n",
    "Calcule el estimado de cada uno sus modelos de lenguaje (el de tuits y el de amlo) para las frases: \"sino gano me voy a la chingada\", \"ya se va a acabar la corrupción\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1700611388168264e-16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.language_model.tweet_probability(\"sino gano me voy a la chingada\",[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.574399840811954e-15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.language_model.tweet_probability(\"ya se va a acabar la corrupción\",[0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo con conferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1874064783191074e-20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences.language_model.tweet_probability(\"sino gano me voy a la chingada\",[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.326693748476923e-17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences.language_model.tweet_probability(\"ya se va a acabar la corrupción\",[0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 5\n",
    "Para cada oración del punto anterior, haga todas las permutaciones posibles. Calcule su probabilidad a cada nueva frase y muestre el top 3 mas probable y el top 3 menos probable (para ambos modelos de lenguaje). Proponga una frase más y haga lo mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra                           Probabilidad\n",
      "--------  ------------------------------  --------------\n",
      "Tweets    la a chingada me voy sino gano     4.52383e-13\n",
      "Tweets    la a chingada me voy gano sino     4.52383e-13\n",
      "Tweets    la voy me chingada a sino gano     4.52383e-13\n",
      "Tweets    la voy me chingada a gano sino     4.52383e-13\n",
      "Tweets    la voy chingada me a sino gano     4.52383e-13\n",
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra                            Probabilidad\n",
      "--------  -------------------------------  --------------\n",
      "Tweets    ya se la va a acabar corrupcion       2.317e-12\n",
      "Tweets    ya se la va a corrupcion acabar       2.317e-12\n",
      "Tweets    ya se la a va acabar corrupcion       2.317e-12\n",
      "Tweets    ya se la a va corrupcion acabar       2.317e-12\n",
      "Tweets    ya va a se la acabar corrupcion       2.317e-12\n",
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra             Probabilidad\n",
      "--------  ----------------  --------------\n",
      "Tweets    quiero hoy decir     7.13275e-05\n",
      "Tweets    quiero decir hoy     7.13275e-05\n",
      "Tweets    hoy quiero decir     5.98933e-05\n",
      "Tweets    hoy decir quiero     5.98933e-05\n",
      "Tweets    decir hoy quiero     3.10356e-05\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from tabulate import tabulate\n",
    "dataset = {\"pharses\": [\"sino gano me voy a la chingada\",\n",
    "                       \"ya se va a acabar la corrupción\",\n",
    "                       \"hoy quiero decir\"],\n",
    "           \"models\": {\"Conferencia\": conferences.language_model.tweet_probability,\n",
    "                      \"Tweets\": tweets.language_model.tweet_probability}}\n",
    "resultados = []\n",
    "for pharse in dataset[\"pharses\"]:\n",
    "    print(\"\\n{}\".format(\"-\"*40))\n",
    "    tokens = tokenize(pharse)\n",
    "    tokens_len = len(tokens)\n",
    "    results = []\n",
    "    for permutation in permutations(tokens, tokens_len):\n",
    "        pharse_permutation = \" \".join(permutation)\n",
    "        for model in dataset[\"models\"]:\n",
    "            function = dataset[\"models\"][model]\n",
    "            probability = function(pharse_permutation, [0, 0, 1])\n",
    "            results += [[model, pharse_permutation, probability]]\n",
    "    results = sorted(results,\n",
    "                     key=lambda x: x[2],\n",
    "                     reverse=True)\n",
    "    results = results[:5]\n",
    "    print(tabulate(results,\n",
    "                   headers=[\"Modelo\",\n",
    "                            \"Palabra\",\n",
    "                            \"Probabilidad\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
