{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giovanni Gamaliel LÃ³pez Padilla\n",
    "### Procesamiento de lenguaje natural\n",
    "### Tarea 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "#### OrganizaciÃ³n de la carpeta\n",
    "\n",
    "```bash\n",
    "â”œâ”€â”€ Data\n",
    "â”‚  â”œâ”€â”€ conferences\n",
    "â”‚  â”‚  â”œâ”€â”€ 2018-12-07\n",
    "â”‚  â”‚  â”œâ”€â”€ 2018-12-10\n",
    "â”‚  â”‚  â”œâ”€â”€ .........\n",
    "â”‚  â”‚  â”œâ”€â”€ 2021-01-21\n",
    "â”‚  â”‚  â””â”€â”€ 2021-01-22\n",
    "â”‚  â”œâ”€â”€ mex_train.txt\n",
    "â”‚  â”œâ”€â”€ mex_train_labels.txt\n",
    "â”‚  â”œâ”€â”€ mex_val.txt\n",
    "â”‚  â””â”€â”€ mex_val_labels.txt\n",
    "â”œâ”€â”€ Modules\n",
    "â”‚  â”œâ”€â”€ datasets.py\n",
    "â”‚  â”œâ”€â”€ dictionary.py\n",
    "â”‚  â”œâ”€â”€ functions.py\n",
    "â”‚  â”œâ”€â”€ maÃ±aneras.py\n",
    "â”‚  â”œâ”€â”€ models.py\n",
    "â”‚  â”œâ”€â”€ tweets.py\n",
    "â”‚  â””â”€â”€ vocabulary.py\n",
    "â””â”€â”€ Tarea04.ipynb\n",
    "```\n",
    "\n",
    "Las funciones y clases contenidad en los archivos de la carpeta ``Modules`` se encuentran contenidas en el notebook.\n",
    "\n",
    "Si se quiere cambiar la posiciÃ³n de los archivos de datos debera modificarse la funciÃ³n ``obtain_parameters`` en los apartados correspondientes a cada base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import bigrams as bigrams_nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from numpy import array, log, zeros, exp\n",
    "from nltk import FreqDist,ngrams\n",
    "from unidecode import unidecode\n",
    "from tabulate import tabulate\n",
    "from numpy.linalg import norm\n",
    "from random import choice\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_parameters() -> dict:\n",
    "    \"\"\"\n",
    "    Obtiene las rutas y nombres de los archivos que seran usados\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        # Ruta de los archivos\n",
    "        \"path data\": \"Data/\",\n",
    "        \"path graphics\": \"Graphics/\",\n",
    "        \"path results\": \"Results/\",\n",
    "        \"path conferences\": \"Data/conferences/\",\n",
    "        # Archivos de entrenamiento\n",
    "        \"train\": {\n",
    "            \"data\": \"mex_train.txt\",\n",
    "            \"labels\": \"mex_train_labels.txt\"\n",
    "        },\n",
    "        # Archivos de validacion\n",
    "        \"validation\": {\n",
    "            \"data\": \"mex_val.txt\",\n",
    "            \"labels\": \"mex_val_labels.txt\"\n",
    "        },\n",
    "        \"max words\": 5000,\n",
    "        \"max bigrams\": 1000,\n",
    "        \"lambda list\": [[1/3, 1/3, 1/3],\n",
    "                        [0.4, 0.4, 0.2],\n",
    "                        [0.2, 0.4, 0.4],\n",
    "                        [0.5, 0.4, 0.1],\n",
    "                        [0.1, 0.4, 0.5]]\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Realiza la tokenizacion de un texto dado\n",
    "    ------------\n",
    "    Inputs:\n",
    "    text -> string de texto\n",
    "\n",
    "    ------------\n",
    "    Outputs:\n",
    "    aux -> lista de tokens\n",
    "    \"\"\"\n",
    "    # ExpresiÃ³n para obtener palabras\n",
    "    reg_exp = r\"<?/?[A-Z|a-z]+>?\"\n",
    "    tokenizer = TweetTokenizer().tokenize\n",
    "    text = unidecode(text)\n",
    "    # coniverto texto a minÃºsculas y limpio\n",
    "    aux = re.findall(reg_exp, text.lower())\n",
    "    aux = ' '.join(aux)\n",
    "    # tokenizo\n",
    "    aux = tokenizer(aux)\n",
    "    return aux\n",
    "\n",
    "\n",
    "def ls(path: str) -> list:\n",
    "    return sorted(listdir(path))\n",
    "\n",
    "\n",
    "def join_path(path: str, filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Une la direccion de un archivo con su nombre\n",
    "    \"\"\"\n",
    "    return \"{}{}\".format(path, filename)\n",
    "\n",
    "\n",
    "def mask_unknow(tweet: str, vocabulary: list) -> str:\n",
    "    \"\"\"\n",
    "    Enmascaramiento de una oraciÃ³n dado un vocabulario\n",
    "    -----------\n",
    "    Inputs:\n",
    "    + tweet -> string con el tweet a enmascarar\n",
    "    + vocabulary -> vocabulario de los datos de entrenamiento\n",
    "\n",
    "    ------------\n",
    "    Outputs:\n",
    "    tweet_mask -> string con el tweet enmascarado\n",
    "    \"\"\"\n",
    "    # Tokens del tweet dado\n",
    "    tokens = tokenize(tweet)\n",
    "    # Enmascaramiento de los tokens\n",
    "    tweet_mask = [word if word in vocabulary else \"<unk>\"\n",
    "                  for word in tokens]\n",
    "    # Union de los tokens\n",
    "    tweet_mask = \" \".join(tweet_mask)\n",
    "    return tweet_mask\n",
    "\n",
    "\n",
    "class dictionary_class:\n",
    "    \"\"\"\n",
    "    MÃ©todos para crear diccionarios con diferentes informaciones\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def build_word_index(self, vocabulary: list) -> dict:\n",
    "        \"\"\"\n",
    "        Crea un diccionario con la posiciÃ³n de mayor a menor frecuencia de cada palabra. La llave es la palabra a consultar\n",
    "        \"\"\"\n",
    "        # Inicializacion del diccionario\n",
    "        index = dict()\n",
    "        # Inicializacion de la posicion\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            index[word] = i\n",
    "        return index\n",
    "\n",
    "    def build_with_words_and_documents(self, words: dict, data: list) -> dict:\n",
    "        \"\"\"\n",
    "        Crea un diccionario el cual contendra de forma ordenada el indice de cada palabra y su numero de frecuencias en una coleccion\n",
    "        \"\"\"\n",
    "        freq_word_per_document = dict()\n",
    "        word_count = dict()\n",
    "        for i, tweet in enumerate(data):\n",
    "            word_count[i] = 0\n",
    "        for word in words:\n",
    "            freq_word_per_document[word] = word_count\n",
    "        return freq_word_per_document\n",
    "\n",
    "    def obtain_index_word(self, index_word: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Invierte los valores de un diccionario dado. Los values pasan a ser keys y viceversa\n",
    "        \"\"\"\n",
    "        invert_index = {}\n",
    "        for word in index_word:\n",
    "            invert_index[index_word[word]] = word\n",
    "        return invert_index\n",
    "\n",
    "    def sort_dict(self, data: dict, reverse: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Ordena un diccionario\n",
    "        \"\"\"\n",
    "        aux = sorted(data.items(),\n",
    "                     key=lambda item: item[1], reverse=reverse)\n",
    "        dict_sort = {}\n",
    "        for word, value in aux:\n",
    "            dict_sort[word] = value\n",
    "        return dict_sort\n",
    "\n",
    "\n",
    "class vocabulary_class:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def obtain(self, data: list, max_words: int) -> dict:\n",
    "        \"\"\"\n",
    "        Obtiene la lista de una distribucion de frecuencias de palabras ordenada de mayor a menor a partir de una lista de oraciones\n",
    "        \"\"\"\n",
    "        # Inicializacion de la lista que guardara los tokens\n",
    "        corpus = []\n",
    "        for tweet in data:\n",
    "            # Creacion y guardado de los tokens\n",
    "            corpus += tokenize(tweet)\n",
    "        # Creacion de la distribucion de frecuencias\n",
    "        vocabulary = FreqDist(corpus)\n",
    "        vocabulary = self.sort_freqdist(vocabulary)\n",
    "        # print(vocabulary)\n",
    "        vocabulary = self.split_data(vocabulary, max_words)\n",
    "        return vocabulary\n",
    "\n",
    "    def obtain_with_bigrams(self, data: list, max_bigrams: int) -> list:\n",
    "        \"\"\"\n",
    "        Obtiene la lista de una distribucion de frecuencias de palabras ordenada de mayor a menor a partir de una lista de oraciones\n",
    "        \"\"\"\n",
    "        # Inicializacion de la lista que guardara los tokens\n",
    "        corpus_bigrams = []\n",
    "        for tweet in data:\n",
    "            # Creacion y guardado de los tokens\n",
    "            corpus_bigrams += bigrams_nltk(tokenize(tweet))\n",
    "        # Creacion de la distribucion de frecuencias\n",
    "        vocabulary = FreqDist(corpus_bigrams)\n",
    "        vocabulary = self.sort_freqdist(vocabulary)\n",
    "        vocabulary = self.split_data(vocabulary, max_bigrams)\n",
    "        return vocabulary\n",
    "\n",
    "    def sort_freqdist(self, vocabulary: FreqDist) -> list:\n",
    "        \"\"\"\n",
    "        Ordena la lista de distribucion de frecuencias de palabras de mayor frecuencia a menor\n",
    "        \"\"\"\n",
    "        aux = {}\n",
    "        for word in vocabulary:\n",
    "            aux[word] = vocabulary[word]\n",
    "        aux = dictionary_class().sort_dict(aux)\n",
    "        return aux\n",
    "\n",
    "    def split_data(self, data: dict, max_words: int) -> list:\n",
    "        \"\"\"\n",
    "        Realiza la separacion de elementos en una lista dado el numero de elementos que se quieren conservar\n",
    "        \"\"\"\n",
    "        aux = {}\n",
    "        for i, word in enumerate(data):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            aux[word] = data[word]\n",
    "        return aux\n",
    "\n",
    "\n",
    "class probability_model_class:\n",
    "    \"\"\"\n",
    "    Contenido para enmascarar palabras que no estan contenidas en un vocabulario y calculo de las probabilidades de unigramas, bigramas y trigramas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def obtain_unigram_probabilities_Laplace(self, data: list) -> dict:\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades de cada unigrama en los datos dado\n",
    "        --------------\n",
    "        Inputs:\n",
    "        + data -> lista de strings con cada tweet\n",
    "\n",
    "        Output:\n",
    "        + probability -> diccionario con las probabilidades de cada palabra en el vocabulario\n",
    "        \"\"\"\n",
    "        # Tokens de cada oracion\n",
    "        tokens = []\n",
    "        for tweet in data:\n",
    "            # Token de cada tweet\n",
    "            tokens += tokenize(tweet)\n",
    "        # Numero de palabras en el documento\n",
    "        self.words_len = len(tokens)\n",
    "        # Frecuencias de las palabras\n",
    "        self.unigram_fdist = FreqDist(tokens)\n",
    "        # TamaÃ±o del vocabulario\n",
    "        n_vocabulary = len(self.unigram_fdist)\n",
    "        # Probabilidades de unigramas\n",
    "        probability = {\n",
    "            word: (count + 1.0) / (self.words_len + n_vocabulary)\n",
    "            for word, count in self.unigram_fdist.items()\n",
    "        }\n",
    "        self.unigram_probability = probability.copy()\n",
    "        return probability\n",
    "\n",
    "    def obtain_ngrams_probabilities_Laplace(self, data: list, ngram: int) -> dict:\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades de cada ngrama en los datos dado\n",
    "        --------------\n",
    "        Inputs:\n",
    "        + data -> lista de strings con cada tweet\n",
    "        + ngram -> entero que indica el nÃºmero de ngramas a calcular\n",
    "\n",
    "        Output:\n",
    "        + probability -> diccionario con las probabilidades de cada bigrama en el vocabulario\n",
    "        \"\"\"\n",
    "        # Creacion de la lista de tokens\n",
    "        tokens = []\n",
    "        for tweet in data:\n",
    "            # Tokens de cada tweet\n",
    "            tokens += tokenize(tweet)\n",
    "        self.tokens = tokens.copy()\n",
    "        # ngramas en el documento\n",
    "        n_grams = ngrams(tokens, n=ngram)\n",
    "        # frecuencia de cada ngrama\n",
    "        ngram_fdist = FreqDist(n_grams)\n",
    "        # numero total de ngramas\n",
    "        ngram_len = len(ngram_fdist)\n",
    "        # inicializacion de la probabilidades\n",
    "        probabilities = {}\n",
    "        # Apartado para bigrama\n",
    "        if ngram == 2:\n",
    "            for (word_i, word_j), count in ngram_fdist.items():\n",
    "                # Frecuencia de la palabra anterior en el bigrama\n",
    "                count_word_i = self.unigram_fdist[word_i]\n",
    "                # Probabilidad del bigrama\n",
    "                probabilities[(word_j, word_i)] = (\n",
    "                    count + 1.0) / (count_word_i + ngram_len)\n",
    "            self.bigram_probability = probabilities.copy()\n",
    "        # Apartado para trigrama\n",
    "        if ngram == 3:\n",
    "            # bigramas en el documento\n",
    "            bigrams = ngrams(tokens, n=2)\n",
    "            # frecuencias de cada bograma\n",
    "            self.bigram_fdist = FreqDist(bigrams)\n",
    "            for (word_i, word_j, word_k), count in ngram_fdist.items():\n",
    "                # frecuencia del bigrama\n",
    "                count_fs = self.bigram_fdist[(word_i, word_j)]\n",
    "                # Suavizado con laplace\n",
    "                probabilities[(word_k, word_i, word_j)] = (\n",
    "                    count + 1.0) / (count_fs + ngram_len)\n",
    "            self.trigram_probability = probabilities.copy()\n",
    "        return probabilities\n",
    "\n",
    "    def obtain_unigram_probability(self, word: str) -> float:\n",
    "        \"\"\"\n",
    "        Obtiene la probabilidad que tiene un tweet siguiendo una probabilidad de unigramas\n",
    "        --------------\n",
    "        Input:\n",
    "        + tweet -> string del tweet\n",
    "        \"\"\"\n",
    "        if not word in self.unigram_probability:\n",
    "            word = \"<unk>\"\n",
    "        probability = self.unigram_probability[word]\n",
    "        return probability\n",
    "\n",
    "    def compute_ngram_probability(self,\n",
    "                                  tweet: str,\n",
    "                                  vocabulary: list,\n",
    "                                  ngram: int = 2) -> float:\n",
    "        \"\"\"\n",
    "        Calculo de la probabilidad de la oracion dada\n",
    "        ----------\n",
    "        Inputs:\n",
    "        + tweet -> string tweet a calcular su probabilidad\n",
    "        + vocabulary -> vocabulario de los datos de entrenamiento\n",
    "        + ngram -> entero que indica la cantidad de ngramas a tomar\n",
    "\n",
    "        -----------\n",
    "        Output:\n",
    "        probability -> probabilidad del tweet dado\n",
    "        \"\"\"\n",
    "        # enmascaro oracion\n",
    "        tweet = mask_unknow(tweet, vocabulary)\n",
    "        # Concateno inicio y fin de oraciÃ³n\n",
    "        s_init = \"<s>\"\n",
    "        s_fin = \"</s>\"\n",
    "        tweet = \"{}{}{}\".format(s_init, tweet, s_fin)\n",
    "        tweet = tokenize(tweet)\n",
    "        # TamaÃ±o del vocabulario\n",
    "        vocabulary_len = len(vocabulary)\n",
    "        probability = 1\n",
    "        # Apartado para bigrama\n",
    "        if ngram == 2:\n",
    "            # Frecuencia de los unigramas\n",
    "            for i in range(len(tweet) - 1):\n",
    "                word_i = tweet[i]\n",
    "                word_j = tweet[i + 1]\n",
    "                if (word_j, word_i) in self.bigram_probability:\n",
    "                    probability *= self.bigram_probability[(word_j, word_i)]\n",
    "                # Si la palabra no se encuentra se da una probabilidad\n",
    "                else:\n",
    "                    freq_word_i = self.unigram_fdist[word_i]\n",
    "                    probability *= 1.0 / (freq_word_i + vocabulary_len)\n",
    "        # Apartado para trigramas\n",
    "        if ngram == 3:\n",
    "            # Bigramas en la oracion\n",
    "            bigrams = ngrams(self.tokens, n=2)\n",
    "            # Freceucnia de bigramas\n",
    "            self.bigrams_fdist = FreqDist(bigrams)\n",
    "            # TamaÃ±o e bigramas\n",
    "            bigram_len = len(self.bigrams_fdist)\n",
    "            for i in range(len(tweet) - 2):\n",
    "                word_i = tweet[i]\n",
    "                word_j = tweet[i + 1]\n",
    "                word_k = tweet[i + 2]\n",
    "                if (word_k, word_i, word_j) in self.trigram_probability:\n",
    "                    probability *= self.trigram_probability[(\n",
    "                        word_k, word_i, word_j)]\n",
    "                # Si no se encuentra se da una probabilidad\n",
    "                else:\n",
    "                    count_fs = 0\n",
    "                    if (word_i, word_j) in self.bigrams_fdist:\n",
    "                        count_fs = self.bigrams_fdist[(word_i, word_j)]\n",
    "                    conditional_prop = 1 / (count_fs + bigram_len)\n",
    "                    probability *= conditional_prop\n",
    "        return probability\n",
    "\n",
    "    def obtain_ngram_probability(self, ngram: list) -> float:\n",
    "        \"\"\"\n",
    "        Obtiene la probabilidad de un ngrama dado\n",
    "        -----------\n",
    "        Inputs:\n",
    "        + ngram -> lista de ngramas\n",
    "\n",
    "        -----------\n",
    "        Output:\n",
    "        + probability -> probabilidad del ngrama dado\n",
    "        \"\"\"\n",
    "        probability = 1.0\n",
    "        ngram_len = len(ngram)\n",
    "        # Caso para bigrama\n",
    "        if ngram_len == 2:\n",
    "            for i in range(ngram_len - 1):\n",
    "                word_i = ngram[i]\n",
    "                word_j = ngram[i + 1]\n",
    "                if (word_j, word_i) in self.bigram_probability:\n",
    "                    probability *= self.bigram_probability[(word_j, word_i)]\n",
    "                # Si la probabilidad no existe se da con al menos un conteo\n",
    "                else:\n",
    "                    freq_word_i = self.unigram_fdist[word_i]\n",
    "                    probability *= 1.0 / (freq_word_i + self.words_len)\n",
    "        # Caso para trigramas\n",
    "        if ngram_len == 3:\n",
    "            for i in range(ngram_len - 2):\n",
    "                word_i = ngram[i]\n",
    "                word_j = ngram[i + 1]\n",
    "                word_k = ngram[i + 2]\n",
    "                if (word_k, word_i, word_j) in self.trigram_probability:\n",
    "                    probability *= self.trigram_probability[(\n",
    "                        word_k, word_i, word_j)]\n",
    "                # Si la probabilidad no existe se da con al menos un conteo\n",
    "                else:\n",
    "                    count_fs = 0.0\n",
    "                    if (word_i, word_j) in self.bigram_fdist:\n",
    "                        count_fs = self.bigram_fdist[(word_i, word_j)]\n",
    "                    conditional_prop = 1.0 / (count_fs + self.words_len)\n",
    "                    probability *= conditional_prop\n",
    "        return probability\n",
    "\n",
    "\n",
    "class language_model_class:\n",
    "\n",
    "    def __init__(self, data_tr: list, data_test: list, data_val: list, vocabulary: dict):\n",
    "        self.probability_model = probability_model_class()\n",
    "        self.data_tr = data_tr\n",
    "        self.data_test = data_test\n",
    "        self.data_val = data_val\n",
    "        self.vocabulary = vocabulary.keys()\n",
    "        self.obtain_probabilities()\n",
    "\n",
    "    def obtain_probabilities(self) -> None:\n",
    "        self.unigram_probability = self.probability_model.obtain_unigram_probabilities_Laplace(\n",
    "            self.data_tr)\n",
    "        self.bigram_probability = self.probability_model.obtain_ngrams_probabilities_Laplace(\n",
    "            self.data_tr,\n",
    "            ngram=2,\n",
    "        )\n",
    "        self.tigram_probability = self.probability_model.obtain_ngrams_probabilities_Laplace(\n",
    "            self.data_tr,\n",
    "            ngram=3,\n",
    "        )\n",
    "        # Preparo modelo para evaluaciÃ³n\n",
    "        tokens = []\n",
    "        for tweet in self.data_tr:\n",
    "            tokens += tokenize(tweet)\n",
    "        # Total de palabras\n",
    "        self.words_len = len(tokens)\n",
    "        bigrams = ngrams(tokens, n=2)\n",
    "        # Frecuencias bigramas\n",
    "        self.bigram_fdist = FreqDist(bigrams)\n",
    "        # Frecuencias unigramas\n",
    "        self.unigram_fdist = FreqDist(tokens)\n",
    "\n",
    "    def compute_perplexity(self, lambda_values: list, use_data_test: bool = True) -> float:\n",
    "        tokens = []\n",
    "        if use_data_test:\n",
    "            data = self.data_test\n",
    "        else:\n",
    "            data = self.data_val\n",
    "        for tweet in data:\n",
    "            tokens += tokenize(tweet)\n",
    "        trigrams = ngrams(tokens, n=3)\n",
    "        perplexity = 0.0\n",
    "        for (word_i, word_j, word_k) in trigrams:\n",
    "            aux = 0.0\n",
    "            aux += lambda_values[0] * self.probability_model.obtain_ngram_probability(\n",
    "                (word_i, word_j, word_k),)\n",
    "            aux += lambda_values[1] * self.probability_model.obtain_ngram_probability(\n",
    "                (word_i, word_j),)\n",
    "            aux += lambda_values[2] * self.probability_model.obtain_unigram_probability(\n",
    "                word_i)\n",
    "            perplexity += log(aux)\n",
    "        perplexity = -perplexity / self.words_len\n",
    "        return perplexity\n",
    "\n",
    "    def tweet_probability(self, tweet: str, lambda_values: list, add_s_tokens: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de un tweet por medio de la interpolacion\n",
    "        ----------------\n",
    "        Inputs:\n",
    "        + tweet -> string del tweet a calcular su probabilidad\n",
    "        + lambda_values -> lista de lambdas para los pesos de cada ngrama\n",
    "\n",
    "        ----------------\n",
    "        Outputs:\n",
    "        + probability -> probabilidad del tweet dado\n",
    "        \"\"\"\n",
    "        # Enmascaro palabras desconocidas\n",
    "        if add_s_tokens:\n",
    "            tweet = mask_unknow(tweet, self.vocabulary)\n",
    "            tweet = \"<s>{}</>\".format(tweet)\n",
    "        tokens = tokenize(tweet)\n",
    "        trigrams = ngrams(tokens, n=3)\n",
    "        probability = 1.0\n",
    "        for (word_i, word_j, word_k) in trigrams:\n",
    "            aux = 0\n",
    "            # Compruebo valores de lambda\n",
    "            if lambda_values[0] != 0:\n",
    "                aux += lambda_values[0] * self.probability_model.obtain_ngram_probability(\n",
    "                    (word_i, word_j, word_k),)\n",
    "            if lambda_values[1] != 0:\n",
    "                aux += lambda_values[1] * self.probability_model.obtain_ngram_probability(\n",
    "                    (word_i, word_j),)\n",
    "            if lambda_values[2] != 0:\n",
    "                aux += lambda_values[2] * self.probability_model.obtain_unigram_probability(\n",
    "                    word_i)\n",
    "            probability *= aux\n",
    "        return probability\n",
    "\n",
    "    def apply_expectation_maximization(self, lambda_test: list = [], iterations: int = 5) -> array:\n",
    "        results = []\n",
    "        ngrams = 3\n",
    "        if not len(lambda_test):\n",
    "            lambda_test = [1/ngrams for i in range(ngrams)]\n",
    "        perplexity = exp(self.compute_perplexity(lambda_test))\n",
    "        results += [[\"Inicio\",\n",
    "                     lambda_test.copy(),\n",
    "                     sum(lambda_test),\n",
    "                     perplexity]]\n",
    "        data_len = len(self.data_val)\n",
    "        # Vectores de distribuciones q_m\n",
    "        dist = zeros((data_len, ngrams), dtype=float)\n",
    "        for iteration in range(iterations):\n",
    "            # Ciclo sobre tokens de validaciÃ³n\n",
    "            for i, tweet in enumerate(self.data_val):\n",
    "                dist[i, 0] = self.tweet_probability(tweet,\n",
    "                                                    [lambda_test[0], 0, 0],\n",
    "                                                    add_s_tokens=False)\n",
    "                dist[i, 1] = self.tweet_probability(tweet,\n",
    "                                                    [0, lambda_test[1], 0],\n",
    "                                                    add_s_tokens=False)\n",
    "                dist[i, 2] = self.tweet_probability(tweet,\n",
    "                                                    [0, 0, lambda_test[2]],\n",
    "                                                    add_s_tokens=False)\n",
    "                # Normalizo vector\n",
    "                dist[i] = dist[i] / norm(dist[i])\n",
    "            # Update lambdas\n",
    "            for i in range(ngrams):\n",
    "                lambda_test[i] = sum(dist[:, i]) / data_len\n",
    "            perplexity = exp(self.compute_perplexity(lambda_test))\n",
    "            results += [[\"IteraciÃ³n {}\".format(iteration+1),\n",
    "                         lambda_test.copy(),\n",
    "                         sum(lambda_test),\n",
    "                         perplexity]]\n",
    "\n",
    "        print(tabulate(results,\n",
    "                       headers=[\"Iteracion\", \"lambdas\", \"Suma\", \"Perplexidad\"]))\n",
    "        return lambda_test\n",
    "\n",
    "\n",
    "class tweetear_model:\n",
    "    def __init__(self, language_model: language_model_class, lambdas: list):\n",
    "        self.language_model = language_model\n",
    "        self.lambdas = lambdas\n",
    "\n",
    "    def autocomplete(self, init_text: list):\n",
    "        # Creo todas las posibles oraciones\n",
    "        tweets = []\n",
    "        for word in self.language_model.vocabulary:\n",
    "            value = \"{} {}\".format(init_text, word)\n",
    "            tweets += [value]\n",
    "        probabilities = []\n",
    "        for i, tweet in enumerate(tweets):\n",
    "            probabilities += [[self.language_model.tweet_probability(tweet,\n",
    "                                                                     self.lambdas), i]]\n",
    "        # Ordeno oraciones por probabilidad\n",
    "        probabilities.sort(reverse=True)\n",
    "        tweet = tweets[probabilities[0][1]]\n",
    "        return tweet\n",
    "\n",
    "    def write(self, init_text: list, max_words: int = 50) -> str:\n",
    "        text = tokenize(init_text)\n",
    "        result = text.copy()\n",
    "        for i in range(max_words):\n",
    "            tweet = self.autocomplete(\" \".join(text))\n",
    "            words = tokenize(tweet)\n",
    "            word = words[-1]\n",
    "            text.pop(0)\n",
    "            text.append(word)\n",
    "            result += [word]\n",
    "            if word == '</s>':\n",
    "                break\n",
    "        result = \" \".join(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class tweets_data:\n",
    "    def __init__(self, parameters: dict) -> None:\n",
    "        self.vocabulary_model = vocabulary_class()\n",
    "        self.dictionary = dictionary_class()\n",
    "        self.parameters = parameters\n",
    "        self.read()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        self.add_s_tokens()\n",
    "        self.obtain_vocabulary(use_mask=True)\n",
    "        self.obtain_word_index()\n",
    "        self.obtain_index_word()\n",
    "        self.data_tr_mask = self.mask_tweets(self.data_tr_mask)\n",
    "        self.data_val_mask = self.mask_tweets(self.data_val_mask)\n",
    "        self.obtain_vocabulary(use_mask=True)\n",
    "        self.obtain_word_index()\n",
    "        self.obtain_index_word()\n",
    "        self.obtain_data_test()\n",
    "        self.language_model = language_model_class(self.data_tr_mask,\n",
    "                                                   self.data_test_mask,\n",
    "                                                   self.data_val_mask,\n",
    "                                                   self.vocabulary)\n",
    "\n",
    "    def get_texts_from_file(self, path_data: str, path_labels: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Obtiene una lista de oraciones a partir de un texto con sus respectivas etiquetas\n",
    "        \"\"\"\n",
    "        # Inicilizacion de las listas\n",
    "        text = []\n",
    "        labels = []\n",
    "        # Apertura de los archivos\n",
    "        with open(path_data, \"r\") as f_data, open(path_labels, \"r\") as f_labels:\n",
    "            # Recoleccion de las oraciones\n",
    "            for tweet in f_data:\n",
    "                text += [tweet]\n",
    "            # Recoleccion de las etiquedas\n",
    "            for label in f_labels:\n",
    "                labels += [label]\n",
    "        # Etiquedas a enteros\n",
    "        labels = list(map(int, labels))\n",
    "        return text, labels\n",
    "\n",
    "    def read(self) -> None:\n",
    "        \"\"\"\n",
    "        Lectura de los datos de entrenamiento y validacion\n",
    "        \"\"\"\n",
    "        # Definicion de las rutas de cada archivo de datos y validacion\n",
    "        path_data_tr = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"train\"][\"data\"],\n",
    "        )\n",
    "        path_label_tr = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"train\"][\"labels\"],\n",
    "        )\n",
    "        path_data_val = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"validation\"][\"data\"],\n",
    "        )\n",
    "        path_label_val = join_path(\n",
    "            self.parameters[\"path data\"],\n",
    "            self.parameters[\"validation\"][\"labels\"],\n",
    "        )\n",
    "        # Lectura de las oraciones y etiquetas de los datos de entrenamiento\n",
    "        self.data_tr, self.labels_tr = self.get_texts_from_file(\n",
    "            path_data_tr,\n",
    "            path_label_tr,\n",
    "        )\n",
    "        # Lectura de las oraciones y etiquetas de los datos de validaciÃ³n\n",
    "        self.data_val, self.labels_val = self.get_texts_from_file(\n",
    "            path_data_val,\n",
    "            path_label_val,\n",
    "        )\n",
    "\n",
    "    def add_s_tokens(self) -> None:\n",
    "        self.data_tr_mask = [\"<s>{}</s>\".format(tweet)\n",
    "                             for tweet in self.data_tr]\n",
    "        self.data_val_mask = [\"<s>{}</s>\".format(tweet)\n",
    "                              for tweet in self.data_val]\n",
    "\n",
    "    def obtain_vocabulary(self, use_mask: bool) -> None:\n",
    "        if use_mask:\n",
    "            data = self.data_tr_mask\n",
    "        else:\n",
    "            data = self.data_tr\n",
    "        self.vocabulary = self.vocabulary_model.obtain(data,\n",
    "                                                       self.parameters[\"max words\"])\n",
    "\n",
    "    def obtain_word_index(self) -> None:\n",
    "        self.word_index = self.dictionary.build_word_index(self.vocabulary)\n",
    "\n",
    "    def obtain_index_word(self) -> None:\n",
    "        self.index_word = self.dictionary.obtain_index_word(self.word_index)\n",
    "\n",
    "    def mask_tweets(self, tweets: list) -> None:\n",
    "        tweets_mask = []\n",
    "        for tweet in tweets:\n",
    "            tweet_mask = mask_unknow(tweet,\n",
    "                                     self.vocabulary.keys())\n",
    "            tweets_mask += [tweet_mask]\n",
    "        return tweets_mask\n",
    "\n",
    "    def obtain_data_test(self) -> None:\n",
    "        self.data_tr_mask, self.data_test_mask = train_test_split(self.data_tr_mask,\n",
    "                                                                  train_size=0.89,\n",
    "                                                                  test_size=0.11,\n",
    "                                                                  random_state=12345)\n",
    "\n",
    "    def obtain_perplexity(self, use_data_test: bool) -> None:\n",
    "        results = []\n",
    "        for lambda_i in self.parameters[\"lambda list\"]:\n",
    "            perplexity = self.language_model.compute_perplexity(lambda_i,\n",
    "                                                                use_data_test=use_data_test)\n",
    "            results += [[lambda_i, exp(perplexity)]]\n",
    "        print(tabulate(results, headers=[\"Lambda\", \"Perplexity\"]))\n",
    "\n",
    "\n",
    "class AMLO_conferences_model(tweets_data):\n",
    "    def __init__(self, parameters: dict) -> None:\n",
    "        self.vocabulary_model = vocabulary_class()\n",
    "        self.dictionary = dictionary_class()\n",
    "        self.parameters = parameters\n",
    "        self.read()\n",
    "        self.obtain_data_val()\n",
    "        self.initialize()\n",
    "\n",
    "    def read(self) -> list:\n",
    "        \"\"\"\n",
    "        Realiza la lectura de todas las conferencias y las reune en un solo string\n",
    "        Input:\n",
    "            String: path -> Direccion donde se encuentran todos los archivos\n",
    "\n",
    "        Output:\n",
    "            String: Texto plano\n",
    "        \"\"\"\n",
    "        files = ls(self.parameters[\"path conferences\"])\n",
    "        self.data = []\n",
    "        for file in files:\n",
    "            # Direccion y nombre del archivo\n",
    "            filename = join_path(self.parameters[\"path conferences\"],\n",
    "                                 file)\n",
    "            # Apertura del archivo\n",
    "            file_data = open(filename, \"r\", encoding=\"utf-8\")\n",
    "            file_text = file_data.read()\n",
    "            file_text = file_text.lower()\n",
    "            file_text = unidecode(file_text)\n",
    "            file_text = tokenize(file_text)\n",
    "            file_text = \" \".join(file_text)\n",
    "            # Concadenacion del texto\n",
    "            self.data += [file_text]\n",
    "            # Cierre del texto\n",
    "            file_data.close()\n",
    "\n",
    "    def obtain_data_val(self) -> None:\n",
    "        self.data_tr, self.data_val = train_test_split(self.data,\n",
    "                                                       train_size=0.9,\n",
    "                                                       test_size=0.1,\n",
    "                                                       random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Modelos de lenguaje y evaluaciÃ³n\n",
    "##### Punto 1\n",
    "Preprocese todos los tuits de agresividad (positivos y negativos) segÃºn su intu- iciÃ³n para construir un buen corpus para un modelo de lenguaje (e.g., solo palabras en minÃºscula, etc.). Agregue tokens especiales de ``<s>`` y ``</s>`` segÃºn usted considere (e.g., al inicio y final de cada tuit). Defina su vocabulario y enmascare con ``<unk>`` toda palabra que no estÃ© en su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.datasets import obtain_parameters\n",
    "from Modules.tweets import tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = obtain_parameters()\n",
    "tweets = tweets_data(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 2\n",
    "\n",
    "Entrene tres modelos de lenguaje sobre todos los tuits: $ğ‘ƒ_{ğ‘¢ğ‘›ğ‘–ğ‘”ğ‘Ÿğ‘ğ‘šğ‘ğ‘ }(ğ‘¤_1^ğ‘›)$, $ğ‘ƒ_{ğ‘ğ‘–ğ‘”ğ‘Ÿğ‘ğ‘šğ‘ğ‘ }(ğ‘¤_1^ğ‘›)$, $ğ‘ƒ_{ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘Ÿğ‘ğ‘šğ‘ğ‘ }(ğ‘¤_1^ğ‘›)$. Para cada uno proporcione una interfaz (funciÃ³n) sencilla para $ğ‘ƒ_{ğ‘›âˆ’ğ‘”ğ‘Ÿğ‘ğ‘šğ‘}(ğ‘¤_1^ğ‘›)$ y $ğ‘ƒ_{ğ‘›âˆ’ğ‘”ğ‘Ÿğ‘ğ‘šğ‘}(ğ‘¤_1^ğ‘›|ğ‘¤_{ğ‘›âˆ’ğ‘ +1}^{n-1})$. Los modelos deben tener una estrategia comÃºn para lidiar consecuencias no vistas. Puede optar por un suavizamiento Laplace o un Good-Turing discounting. Muestre un par de ejemplos de como funciona, al menos uno con una palabra fuera del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = tweets.language_model\n",
    "probability = language_model.probability_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023423631608247637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_unigram_probability(\"bien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013655031879247502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_unigram_probability(\"hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1070641765103124e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"bueno\", \"esto\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1075668970405812e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"hola\", \"como\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1077018509697929e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"como\", \"estas\", \"plataformas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1077141211396162e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability.obtain_ngram_probability((\"hola\", \"como\", \"estas\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 3\n",
    "\n",
    "Construya un modelo interpolado con valores $\\lambda$ fijos:\n",
    "\n",
    "$$\n",
    " \\hat{P}(w_ğ‘› |ğ‘¤_{ğ‘›âˆ’2}ğ‘¤_{ğ‘›âˆ’1}) = \\lambda_1 ğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{ğ‘›âˆ’2}ğ‘¤_{ğ‘›âˆ’1}) + \\lambda_2 ğ‘ƒ(ğ‘¤_ğ‘› |ğ‘¤_{ğ‘›âˆ’2}ğ‘¤_{ğ‘›âˆ’1}) + \\lambda_3 ğ‘ƒ(ğ‘¤_ğ‘›) \\nonumber\n",
    "$$ \n",
    "\n",
    "Para ello experimente con el modelo en particiones estratificadas de 80%, 10% y 10% para entrenar (train), ajuste de parÃ¡metros (val) y prueba (test) respectivamente. Muestre como bajan o suben las perplejidades en validaciÃ³n, finalmente pruebe una vez en test. Para esto puede explorar algunos valores $\\lambda$ y elija el mejor, i.e., \n",
    "$$\n",
    "\\lambda_1 = \\left[\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\right] \\\\\n",
    "\\lambda_2 = [0.4, 0.4, 0.2] \\\\ \n",
    "\\lambda_3 = [0.2, 0.4, 0.4] \\\\ \n",
    "\\lambda_4 = [0.5, 0.4, 0.1] \\\\ \n",
    "\\lambda_5 =[0.1, 0.4, 0.5] \\\\ \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda                                                          Perplexity\n",
      "------------------------------------------------------------  ------------\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]       2.2506\n",
      "[0.4, 0.4, 0.2]                                                    2.35088\n",
      "[0.2, 0.4, 0.4]                                                    2.20592\n",
      "[0.5, 0.4, 0.1]                                                    2.48767\n",
      "[0.1, 0.4, 0.5]                                                    2.1582\n"
     ]
    }
   ],
   "source": [
    "tweets.obtain_perplexity(use_data_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda                                                          Perplexity\n",
      "------------------------------------------------------------  ------------\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]       2.15777\n",
      "[0.4, 0.4, 0.2]                                                    2.25321\n",
      "[0.2, 0.4, 0.4]                                                    2.11478\n",
      "[0.5, 0.4, 0.1]                                                    2.38302\n",
      "[0.1, 0.4, 0.5]                                                    2.06914\n"
     ]
    }
   ],
   "source": [
    "tweets.obtain_perplexity(use_data_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) GeneraciÃ³n de texto\n",
    "\n",
    "#### Punto 1\n",
    "\n",
    "Proponga una estrategia con base en Expectation Maximization para encontrar buenos valores de interpolaciÃ³n en $\\hat{P}$ usando todo el dataset de agresividad. Para ello experimente con el modelo en particiones de 80%, 10% y 10% para entrenar (train), ajustar parÃ¡metros (val) y probar (test) respectivamente. 1 Muestre como bajan las perplejidades en 5 iteraciones que usted elija (de todas las que sean necesarias de acuerdo a su EM) en validaciÃ³n, y pruebe una vez en test. Sino logra hacer este punto, haga los siguientes dos con el modelo de lenguaje con $\\lambda$ fijos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion    lambdas                                                               Suma    Perplexidad\n",
      "-----------  ------------------------------------------------------------------  ------  -------------\n",
      "Inicio       [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]             1        2.2506\n",
      "IteraciÃ³n 1  [1.0751024666888301e-09, 2.9347965000825594e-08, 0.99999999999994]       1        2.02979\n",
      "IteraciÃ³n 2  [1.2952031643886892e-36, 1.5460152938022499e-31, 1.0]                    1        2.02979\n",
      "IteraciÃ³n 3  [2.2646548008525604e-117, 2.260066097622663e-101, 1.0]                   1        2.02979\n",
      "IteraciÃ³n 4  [0.0, 7.0606259637826e-311, 1.0]                                         1        2.02979\n",
      "IteraciÃ³n 5  [0.0, 0.0, 1.0]                                                          1        2.02979\n"
     ]
    }
   ],
   "source": [
    "lambdas = tweets.language_model.apply_expectation_maximization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.models import tweetear_model\n",
    "tweetear = tweetear_model(tweets.language_model, [1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 2\n",
    "\n",
    "Haga una funciÃ³n \"tuitear\" con base en su modelo de lenguaje $\\hat{P}$ del Ãºltimo punto. El modelo deberÃ¡ poder parar automÃ¡ticamente cuando genere el sÃ­mbolo de terminaciÃ³n de tuit al final (e.g., ``</s>``), o 50 palabras. Proponga algo para que en los Ãºltimos tokens sea mÃ¡s probable generar el token ``</s>``. Muestre al menos cinco ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> me caga que me <unk> </s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hola pinche putita te pones bien cachonda hija de tu puta madre </s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> gracias facebook pero no son personas que <unk> </s>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> GRACIAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> gracias por resolver mi duda existencial </s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> gracias por\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> pisando <unk> </s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> pisando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> vale verga </s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"<s> vale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 3\n",
    "Use la intuiciÃ³n que ha ganado en esta tarea y los datos de las maÃ±aneras para entrenar un modelo de lenguaje AMLO. Haga una un funciÃ³n \"dar_conferencia()\". GenerÃ© un discurso de 300 palabras y detenga al modelo de forma abrupta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.maÃ±aneras import AMLO_conferences_model\n",
    "parameters[\"max words\"]=20000\n",
    "conferences = AMLO_conferences_model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetear = tweetear_model(conferences.language_model, [1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'presidente es que se <unk> a la gente que no se puede hacer una revision de los estados unidos y canada y'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"presidente es\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buenos dias hoy vamos a tener una reunion con el gobierno de mexico y en el caso de la conferencia de prensa matutina del presidente andres manuel lopez obrador si pero no es un asunto de los estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados unidos y canada y estados'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetear.write(\"buenos dias hoy\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 4\n",
    "Calcule el estimado de cada uno sus modelos de lenguaje (el de tuits y el de amlo) para las frases: \"sino gano me voy a la chingada\", \"ya se va a acabar la corrupciÃ³n\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1700611388168264e-16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.language_model.tweet_probability(\"sino gano me voy a la chingada\",[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.574399840811954e-15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.language_model.tweet_probability(\"ya se va a acabar la corrupciÃ³n\",[0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo con conferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1874064783191074e-20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences.language_model.tweet_probability(\"sino gano me voy a la chingada\",[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.326693748476923e-17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences.language_model.tweet_probability(\"ya se va a acabar la corrupciÃ³n\",[0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 5\n",
    "Para cada oraciÃ³n del punto anterior, haga todas las permutaciones posibles. Calcule su probabilidad a cada nueva frase y muestre el top 3 mas probable y el top 3 menos probable (para ambos modelos de lenguaje). Proponga una frase mÃ¡s y haga lo mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra                           Probabilidad\n",
      "--------  ------------------------------  --------------\n",
      "Tweets    la a chingada me voy sino gano     4.52383e-13\n",
      "Tweets    la a chingada me voy gano sino     4.52383e-13\n",
      "Tweets    la voy me chingada a sino gano     4.52383e-13\n",
      "Tweets    la voy me chingada a gano sino     4.52383e-13\n",
      "Tweets    la voy chingada me a sino gano     4.52383e-13\n",
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra                            Probabilidad\n",
      "--------  -------------------------------  --------------\n",
      "Tweets    ya se la va a acabar corrupcion       2.317e-12\n",
      "Tweets    ya se la va a corrupcion acabar       2.317e-12\n",
      "Tweets    ya se la a va acabar corrupcion       2.317e-12\n",
      "Tweets    ya se la a va corrupcion acabar       2.317e-12\n",
      "Tweets    ya va a se la acabar corrupcion       2.317e-12\n",
      "\n",
      "----------------------------------------\n",
      "Modelo    Palabra             Probabilidad\n",
      "--------  ----------------  --------------\n",
      "Tweets    quiero hoy decir     7.13275e-05\n",
      "Tweets    quiero decir hoy     7.13275e-05\n",
      "Tweets    hoy quiero decir     5.98933e-05\n",
      "Tweets    hoy decir quiero     5.98933e-05\n",
      "Tweets    decir hoy quiero     3.10356e-05\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from tabulate import tabulate\n",
    "dataset = {\"pharses\": [\"sino gano me voy a la chingada\",\n",
    "                       \"ya se va a acabar la corrupciÃ³n\",\n",
    "                       \"hoy quiero decir\"],\n",
    "           \"models\": {\"Conferencia\": conferences.language_model.tweet_probability,\n",
    "                      \"Tweets\": tweets.language_model.tweet_probability}}\n",
    "resultados = []\n",
    "for pharse in dataset[\"pharses\"]:\n",
    "    print(\"\\n{}\".format(\"-\"*40))\n",
    "    tokens = tokenize(pharse)\n",
    "    tokens_len = len(tokens)\n",
    "    results = []\n",
    "    for permutation in permutations(tokens, tokens_len):\n",
    "        pharse_permutation = \" \".join(permutation)\n",
    "        for model in dataset[\"models\"]:\n",
    "            function = dataset[\"models\"][model]\n",
    "            probability = function(pharse_permutation, [0, 0, 1])\n",
    "            results += [[model, pharse_permutation, probability]]\n",
    "    results = sorted(results,\n",
    "                     key=lambda x: x[2],\n",
    "                     reverse=True)\n",
    "    results = results[:5]\n",
    "    print(tabulate(results,\n",
    "                   headers=[\"Modelo\",\n",
    "                            \"Palabra\",\n",
    "                            \"Probabilidad\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
