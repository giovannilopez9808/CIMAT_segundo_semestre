\section*{Problema 02}

\textbf{Deriva el clasificador Bayesiano óptimo para el caso de tres clases y una función de costo simétrica cuando:}

\begin{equation*}
    X|Y=1 \sim \mathcal{N}(\mu_1,\Sigma)\qquad X|Y=2 \sim \mathcal{N}(\mu_2,\Sigma)\qquad X|Y=3 \sim \mathcal{N}(\mu_3,\Sigma)
\end{equation*}

y

\begin{equation*}
    P(Y=1)=2P(Y=2)=P(Y=3)
\end{equation*}

Para una x fija, buscamos la asgianción $\hat{y}(x)$ que minimiza el error

\begin{equation*}
    E_{Y|X=x} [L(y,\hat{y}(x))]
\end{equation*}

En este caso

\begin{align*}
    E_{Y|X=x} [L(y,\hat{y}(x))] = & L(1,\hat{y}(x))\pyx{1}{x} + \\
                                  & L(2,\hat{y}(x))\pyx{2}{x} + \\
                                  & L(3,\hat{y}(x))\pyx{3}{x}
\end{align*}

Si $\hat{y}(x)=1$, entonces

\begin{align*}
    E_{Y|X=x} [L(y,\hat{y}(x))] & =  L(2 ,1)\pyx{2}{x} + L(3,1)\pyx{3}{x} \\
                                & = \pyx{2}{x} + \pyx{3}{x}
\end{align*}

Si $\hat{y}(x)=2$, entonces

\begin{align*}
    E_{Y|X=x} [L(y,\hat{y}(x))] & =  L(1 ,2)\pyx{1}{x} + L(3,2)\pyx{3}{x} \\
                                & = \pyx{1}{x} + \pyx{3}{x}
\end{align*}

Si $\hat{y}(x)=3$, entonces

\begin{align*}
    E_{Y|X=x} [L(y,\hat{y}(x))] & =  L(1 ,3)\pyx{1}{x} + L(2,3)\pyx{2}{x} \\
                                & = \pyx{1}{x} + \pyx{2}{x}
\end{align*}

Usando el teorema de bayes se obtiene que

\footnotesize
\begin{align*}
    \pyx{2}{x} + \pyx{3}{x} & =  \frac{\pxy{x}{2}\py{2}}{\sum_j \pxy{x}{j}\py{j}}+ \frac{\pxy{x}{3}\py{3}}{\sum_j \pxy{x}{j}\py{j}} \\[0.25cm]
    \pyx{1}{x} + \pyx{3}{x} & =  \frac{\pxy{x}{1}\py{1}}{\sum_j \pxy{x}{j}\py{j}}+ \frac{\pxy{x}{3}\py{3}}{\sum_j \pxy{x}{j}\py{j}} \\[0.25cm]
    \pyx{1}{x} + \pyx{2}{x} & =  \frac{\pxy{x}{1}\py{1}}{\sum_j \pxy{x}{j}\py{j}}+ \frac{\pxy{x}{2}\py{2}}{\sum_j \pxy{x}{j}\py{j}} \\
\end{align*}
\normalsize

si se cumpla la condición

\begin{align*}
    \pxy{x}{1}\py{1} & \leq \pxy{x}{2}\py{2} \\[0.25cm]
    \pxy{x}{1}\py{1} & \leq \pxy{x}{3}\py{3}
\end{align*}

entonces se cumple que

\begin{align*}
    E_{Y|X=x} [L(y,1)] & \leq E_{Y|X=x} [L(y,2)] \\
    E_{Y|X=x} [L(y,1)] & \leq E_{Y|X=x} [L(y,3)]
\end{align*}

por lo que elegimos $\hat{y}(x)=1$.

Si se cumpla la condición

\begin{align*}
    \pxy{x}{2}\py{2} & \leq \pxy{x}{1}\py{1} \\[0.25cm]
    \pxy{x}{2}\py{2} & \leq \pxy{x}{3}\py{3}
\end{align*}

entonces se cumple que

\begin{align*}
    E_{Y|X=x} [L(y,2)] & \leq E_{Y|X=x} [L(y,1)] \\
    E_{Y|X=x} [L(y,2)] & \leq E_{Y|X=x} [L(y,3)]
\end{align*}

por lo que elegimos $\hat{y}(x)=2$.

Si se cumpla la condición

\begin{align*}
    \pxy{x}{3}\py{3} & \leq \pxy{x}{1}\py{1} \\[0.25cm]
    \pxy{x}{3}\py{3} & \leq \pxy{x}{2}\py{2}
\end{align*}

entonces se cumple que

\begin{align*}
    E_{Y|X=x} [L(y,3)] & \leq E_{Y|X=x} [L(y,1)] \\
    E_{Y|X=x} [L(y,3)] & \leq E_{Y|X=x} [L(y,2)]
\end{align*}

por lo que elegimos $\hat{y}(x)=3$.


Por lo tanto, para una x fija debemos calcular tres coefiencientes y compararlos con 1 para determinar la clasificación correspondiente. Una alternativa es calcular el logaritmo de los coeficientes y compararlo con 0. Los coeficientes son los siguientes:

\begin{align*}
    \frac{\pxy{x}{1}\py{1}}{\pxy{x}{2}\py{2}} & = \frac{\pxy{x}{1}2\py{2}}{\pxy{x}{2}\py{2}}  = \frac{2\pxy{x}{1}}{\pxy{x}{2}} \\[0.25cm]
    \frac{\pxy{x}{1}\py{1}}{\pxy{x}{3}\py{3}} & = \frac{\pxy{x}{1}\py{3}}{\pxy{x}{3}\py{3}}   = \frac{\pxy{x}{1}}{\pxy{x}{3}}  \\[0.25cm]
    \frac{\pxy{x}{2}\py{2}}{\pxy{x}{3}\py{3}} & = \frac{\pxy{x}{2}\py{2}}{2\pxy{x}{3}\py{2}}  = \frac{\pxy{x}{2}}{2\pxy{x}{3}}
\end{align*}

Dado que $X|Y =j \sim \mathcal{N}(\mu_j=\Sigma)$, entonces calculando los logaritmos se tiene que

\begin{align*}
    \log\left (\frac{\pxy{x}{1}}{\pxy{x}{2}} \right ) & = \log (2) + (\mu_1-\mu_2)^T\Sigma^{-1}x+ \frac{1}{2}(\mu_1^T\Sigma\mu_1-\mu_2^T\Sigma\mu_2) = \ell_{1,2}^Tx + b_{1,2} \\
    \log\left (\frac{\pxy{x}{1}}{\pxy{x}{3}} \right ) & = (\mu_1-\mu_3)^T\Sigma^{-1}x+ \frac{1}{2}(\mu_1^T\Sigma\mu_1-\mu_3^T\Sigma\mu_3)    =\ell_{1,3}^Tx + b_{1,3}          \\
    \log\left (\frac{\pxy{x}{2}}{\pxy{x}{3}} \right ) & = (\mu_2-\mu_2)^T\Sigma^{-1}x+ \frac{1}{2}(\mu_2^T\Sigma\mu_2-\mu_3^T\Sigma\mu_3) -\log 2 = \ell_{2,3}^Tx + b_{2,3}
\end{align*}

por lo tanto

\begin{equation*}
    \hat{y}(x) = \begin{cases}
        1 & \text{para  } \ell_{1,2}^Tx + b_{1,2} \geq 0 \text{  y  } \ell_{1,3}^Tx + b_{1,3} \geq 0 \\
        2 & \text{para  } \ell_{1,3}^Tx + b_{1,3} \leq 0 \text{  y  } \ell_{2,3}^Tx + b_{2,3} \geq 0 \\
        3 & \text{para  } \ell_{2,3}^Tx + b_{2,3} \leq 0 \text{  y  } \ell_{2,3}^Tx + b_{2,3} \leq 0
    \end{cases}
\end{equation*}