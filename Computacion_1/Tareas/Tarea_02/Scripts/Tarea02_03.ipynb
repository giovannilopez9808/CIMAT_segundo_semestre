{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giovanni Gamaliel López Padilla\n",
    "#### Procesamiento de lenguaje natural\n",
    "#### Tarea 02 - parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.9) Utilice el recurso léxico del Consejo Nacional de Investigación de Canadá llamado \"EmoLex\" (https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) para construir una \"Bolsa de Emociones\" de los Tweets de agresividad (Debe usar EmoLex en Español). Para esto, una estrategia sencilla sería enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones (BoE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "# Obtiene las rutas y nombres de los archivos\n",
    "parameters = obtain_parameters()\n",
    "# Lectura de los archivos de datos con sus respectivas etiquetas\n",
    "data_tr, labels_tr, data_val, labels_val = load_data(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectuta de los archivos de EmoLex\n",
    "data_tr_emolex_emotions, data_val_emolex_emotions = load_emolex_data(\n",
    "    parameters,\n",
    "    data_tr,\n",
    "    data_val,\n",
    ")\n",
    "# Obtiene la distribucion de palabras ordenadas de mayor a menor con un maximo de 5000 palabras\n",
    "fdist_tr = obtain_fdist(\n",
    "    data_tr_emolex_emotions,\n",
    "    parameters[\"max words\"],\n",
    ")\n",
    "# Creacion del diccionario con la posicion en la distribucion de palabras\n",
    "word_index = create_dictonary_of_index(fdist_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.10) Evalúa tú BoE clasificando con SVM. Ponga una tabla comparativa a modo de resumen con los tres pesados, normalize cada uno si lo cree conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330  67]\n",
      " [ 56 163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       397\n",
      "           1       0.71      0.74      0.73       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.79      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "binary_bow_tr_emolex = build_binary_bow(\n",
    "    data_tr_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "binary_bow_val_emolex = build_binary_bow(\n",
    "    data_val_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    binary_bow_tr_emolex,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    binary_bow_val_emolex,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Binario\",\n",
    ")\n",
    "results = [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  64]\n",
      " [ 59 160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       397\n",
      "           1       0.71      0.73      0.72       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.78      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "freq_bow_tr_emolex = build_frecuency_bow(\n",
    "    data_tr_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "freq_bow_val_emolex = build_frecuency_bow(\n",
    "    data_val_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    freq_bow_tr_emolex,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    freq_bow_val_emolex,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Frecuencias\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325  72]\n",
      " [ 62 157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       397\n",
      "           1       0.69      0.72      0.70       219\n",
      "\n",
      "    accuracy                           0.78       616\n",
      "   macro avg       0.76      0.77      0.76       616\n",
      "weighted avg       0.78      0.78      0.78       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "tfidf_bow_tr_emolex = build_tfidf_bow(\n",
    "    data_tr_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "tfidf_bow_val_emolex = build_tfidf_bow(\n",
    "    data_val_emolex_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    tfidf_bow_tr_emolex,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    tfidf_bow_val_emolex,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"TFIDF\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323  74]\n",
      " [ 57 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       397\n",
      "           1       0.69      0.74      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.77       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW binaria\n",
    "binary_bow_tr_emolex_norm = normalize(binary_bow_tr_emolex)\n",
    "binary_bow_val_emolex_norm = normalize(binary_bow_val_emolex)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    binary_bow_tr_emolex_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    binary_bow_val_emolex_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Binario normalizado\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  77]\n",
      " [ 52 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       397\n",
      "           1       0.68      0.76      0.72       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.78       616\n",
      "weighted avg       0.80      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW basada en frecuencias\n",
    "freq_bow_tr_emolex_norm = normalize(freq_bow_tr_emolex)\n",
    "freq_bow_val_emolex_norm = normalize(freq_bow_val_emolex)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    freq_bow_tr_emolex_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    freq_bow_val_emolex_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Frecuencias normalizado\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326  71]\n",
      " [ 56 163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       397\n",
      "           1       0.70      0.74      0.72       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.78       616\n",
      "weighted avg       0.80      0.79      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW basada en tfidf\n",
    "tfidf_bow_tr_emolex_norm = normalize(tfidf_bow_tr_emolex)\n",
    "tfidf_bow_val_emolex_norm = normalize(tfidf_bow_val_emolex)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    tfidf_bow_tr_emolex_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    tfidf_bow_val_emolex_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"TFIDF normalizado\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo                  Precision    Recall    F1 Score\n",
      "-----------------------  -----------  --------  ----------\n",
      "Binario                     0.781809  0.787763    0.784485\n",
      "Frecuencias                 0.781888  0.784692    0.783227\n",
      "TFIDF                       0.762691  0.767767    0.764987\n",
      "Binario normalizado         0.76822   0.776664    0.771745\n",
      "Frecuencias normalizado     0.772321  0.784301    0.776816\n",
      "TFIDF normalizado           0.774992  0.782725    0.778309\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0) Utilice el recurso léxico llamado \"Spanish Emotion Lexicon (SEL)\" del Dr. Grigori Sidorov, profesor del Centro de Investigación en Computación (CIC) del Instituto Politécnico Nacional (http://www.cic.ipn.mx/∼sidorov/), para enmascarar cada palabra con su emo- ción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, tf, tfidf). Proponga alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos de SEL\n",
    "data_tr_sel_emotions, data_val_sel_emotions, scores = load_sel_data(\n",
    "    parameters,\n",
    "    data_tr,\n",
    "    data_val,\n",
    ")\n",
    "# Obtiene la distribucion de palabras ordenadas de mayor a menor con un maximo de 5000 palabras\n",
    "fdist_tr = obtain_fdist(\n",
    "    data_tr_sel_emotions,\n",
    "    parameters[\"max words\"],\n",
    ")\n",
    "# Creacion del diccionario con la posicion en la distribucion de palabras\n",
    "word_index = create_dictonary_of_index(fdist_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330  67]\n",
      " [ 49 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       397\n",
      "           1       0.72      0.78      0.75       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.80       616\n",
      "weighted avg       0.82      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "binary_bow_tr_sel = build_binary_bow_with_probabilities(\n",
    "    data_tr_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "binary_bow_val_sel = build_binary_bow_with_probabilities(\n",
    "    data_val_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    binary_bow_tr_sel,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    binary_bow_val_sel,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Binario\",\n",
    ")\n",
    "results = [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  65]\n",
      " [ 50 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       397\n",
      "           1       0.72      0.77      0.75       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.80      0.80      0.80       616\n",
      "weighted avg       0.82      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "freq_bow_tr_sel = build_frecuency_bow_with_probabilities(\n",
    "    data_tr_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "freq_bow_val_sel = build_frecuency_bow_with_probabilities(\n",
    "    data_val_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    freq_bow_tr_sel,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    freq_bow_val_sel,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Frecuencias\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[328  69]\n",
      " [ 59 160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       397\n",
      "           1       0.70      0.73      0.71       219\n",
      "\n",
      "    accuracy                           0.79       616\n",
      "   macro avg       0.77      0.78      0.78       616\n",
      "weighted avg       0.79      0.79      0.79       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creacion de la BoW para los datos de entrenamiento usando pesos binarios\n",
    "tfidf_bow_tr_sel = build_tfidf_bow_with_probabilities(\n",
    "    data_tr_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion de la BoW para los datos de validacion usando pesos binarios\n",
    "tfidf_bow_val_sel = build_tfidf_bow_with_probabilities(\n",
    "    data_val_sel_emotions,\n",
    "    fdist_tr,\n",
    "    word_index,\n",
    "    scores,\n",
    ")\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    tfidf_bow_tr_sel,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    tfidf_bow_val_sel,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"TFIDF\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326  71]\n",
      " [ 49 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       397\n",
      "           1       0.71      0.78      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.79       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW binaria\n",
    "binary_bow_tr_sel_norm = normalize(binary_bow_tr_sel)\n",
    "binary_bow_val_sel_norm = normalize(binary_bow_val_sel)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    binary_bow_tr_sel_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    binary_bow_val_sel_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Binario normalizado\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  73]\n",
      " [ 52 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       397\n",
      "           1       0.70      0.76      0.73       219\n",
      "\n",
      "    accuracy                           0.80       616\n",
      "   macro avg       0.78      0.79      0.78       616\n",
      "weighted avg       0.80      0.80      0.80       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW basada en frecuencias\n",
    "freq_bow_tr_sel_norm = normalize(freq_bow_tr_sel)\n",
    "freq_bow_val_sel_norm = normalize(freq_bow_val_sel)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    freq_bow_tr_sel_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    freq_bow_val_sel_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"Frecuencias normalizado\",\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326  71]\n",
      " [ 47 172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       397\n",
      "           1       0.71      0.79      0.74       219\n",
      "\n",
      "    accuracy                           0.81       616\n",
      "   macro avg       0.79      0.80      0.80       616\n",
      "weighted avg       0.81      0.81      0.81       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion de la BoW basada en tfidf\n",
    "tfidf_bow_tr_sel_norm = normalize(tfidf_bow_tr_sel)\n",
    "tfidf_bow_val_sel_norm = normalize(tfidf_bow_val_sel)\n",
    "# Creacion del modelo\n",
    "grid = create_model(\n",
    "    tfidf_bow_tr_sel_norm,\n",
    "    labels_tr,\n",
    ")\n",
    "# Evaluacion del modelo\n",
    "result = evaluate_model(\n",
    "    tfidf_bow_val_sel_norm,\n",
    "    labels_val,\n",
    "    grid,\n",
    "    \"TFIDF normalizado\"\n",
    ")\n",
    "results += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo                  Precision    Recall    F1 Score\n",
      "-----------------------  -----------  --------  ----------\n",
      "Binario                     0.794006  0.803745    0.798065\n",
      "Frecuencias                 0.795666  0.803981    0.799256\n",
      "TFIDF                       0.773118  0.778395    0.77551\n",
      "Binario normalizado         0.787364  0.798707    0.791845\n",
      "Frecuencias normalizado     0.778768  0.789339    0.782981\n",
      "TFIDF normalizado           0.790907  0.803273    0.795671\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2) En un comentario aparte, discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\". No más de 5 renglones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uilice una estrategia en la cual, cada score es utilizado en la evaluación de la bolsa de trabajo de manera en que el peso $w_{ij}$ \n",
    "\n",
    "$$\n",
    "w_{ij} = \\left\\lbrace\n",
    "\\begin{matrix}\n",
    "w^*_{ij}*p_{word} & \\text{si} & \\exists \\;\\;p_{word}  \\\\\n",
    "w^*_{ij}  & \\text{si} & \\not\\exists \\;\\;p_{word} \n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "donde $w^*_{ij}$ es el peso obtenido de aplicar un pesado binario, por frecuencias o TFIDF. Con esto se incluye la caracterización de la palabra dada por SEL."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
